{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WXu1r8qvSzWf"
   },
   "source": [
    "# Twin-Delayed DDPG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YRzQUhuUTc0J"
   },
   "source": [
    "## Enviroment Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HAHMB0Ze8fU0"
   },
   "outputs": [],
   "source": [
    "import Enviorment_Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oreo/opt/anaconda3/envs/RL_env/lib/python3.7/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = Enviorment_Setting.ETFenv(id = \"0051\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xjm2onHdT-Av"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ikr2p0Js8iB4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from gym import wrappers\n",
    "from gym.spaces import Discrete, Box, Dict\n",
    "from torch.autograd import Variable\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y2nGdtlKVydr"
   },
   "source": [
    "## Step 1: We initialize the Experience Replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u5rW0IDB8nTO"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "\n",
    "    def __init__(self, max_size=1e6):\n",
    "        self.storage = []\n",
    "        self.max_size = max_size\n",
    "        self.ptr = 0\n",
    "\n",
    "    def add(self, transition):\n",
    "        if len(self.storage) == self.max_size:\n",
    "            self.storage[int(self.ptr)] = transition\n",
    "            self.ptr = (self.ptr + 1) % self.max_size\n",
    "        else:\n",
    "            self.storage.append(transition)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        ind = np.random.randint(0, len(self.storage), size=batch_size)\n",
    "        batch_states, batch_next_states, batch_actions, batch_rewards, batch_dones = [], [], [], [], []\n",
    "        for i in ind: \n",
    "            state, next_state, action, reward, done = self.storage[i]\n",
    "            batch_states.append(np.array(state, copy=False))\n",
    "            batch_next_states.append(np.array(next_state, copy=False))\n",
    "            batch_actions.append(np.array(action, copy=False))\n",
    "            batch_rewards.append(np.array(reward, copy=False))\n",
    "            batch_dones.append(np.array(done, copy=False))\n",
    "        return np.array(batch_states), np.array(batch_next_states), np.array(batch_actions), np.array(batch_rewards).reshape(-1, 1), np.array(batch_dones).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jb7TTaHxWbQD"
   },
   "source": [
    "## Step 2: We build one neural network for the Actor model and one neural network for the Actor target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4CeRW4D79HL0"
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "  \n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        super(Actor, self).__init__()\n",
    "        self.layer_1 = nn.Linear(state_dim, 400)\n",
    "        self.layer_2 = nn.Linear(400, 300)\n",
    "        self.layer_3 = nn.Linear(300, action_dim)\n",
    "        self.max_action = max_action\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer_1(x))\n",
    "        x = F.relu(self.layer_2(x))\n",
    "        x = nn.Tanh()(self.layer_3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRDDce8FXef7"
   },
   "source": [
    "## Step 3: We build two neural networks for the two Critic models and two neural networks for the two Critic targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCee7gwR9Jrs"
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "  \n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        # Defining the first Critic neural network\n",
    "        self.layer_1 = nn.Linear(state_dim + action_dim, 400)\n",
    "        self.layer_2 = nn.Linear(400, 300)\n",
    "        self.layer_3 = nn.Linear(300, 1)\n",
    "        # Defining the second Critic neural network\n",
    "        self.layer_4 = nn.Linear(state_dim + action_dim, 400)\n",
    "        self.layer_5 = nn.Linear(400, 300)\n",
    "        self.layer_6 = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x, u):\n",
    "        xu = torch.cat([x, u], 1)\n",
    "        # Forward-Propagation on the first Critic Neural Network\n",
    "        x1 = F.relu(self.layer_1(xu))\n",
    "        x1 = F.relu(self.layer_2(x1))\n",
    "        x1 = self.layer_3(x1)\n",
    "        # Forward-Propagation on the second Critic Neural Network\n",
    "        x2 = F.relu(self.layer_4(xu))\n",
    "        x2 = F.relu(self.layer_5(x2))\n",
    "        x2 = self.layer_6(x2)\n",
    "        return x1, x2\n",
    "\n",
    "    def Q1(self, x, u):\n",
    "        xu = torch.cat([x, u], 1)\n",
    "        x1 = F.relu(self.layer_1(xu))\n",
    "        x1 = F.relu(self.layer_2(x1))\n",
    "        x1 = self.layer_3(x1)\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzIDuONodenW"
   },
   "source": [
    "## Steps 4 to 15: Training Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zzd0H1xukdKe"
   },
   "outputs": [],
   "source": [
    "# Selecting the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Building the whole Training Process into a class\n",
    "\n",
    "class TD3(object):\n",
    "  \n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        \n",
    "        self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters())\n",
    "        \n",
    "        self.critic = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_target = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters())\n",
    "        \n",
    "        self.max_action = max_action\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.Tensor(state.reshape(1, -1)).to(device)\n",
    "        return self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "    def train(self, replay_buffer, iterations, batch_size=100, discount=0.99, tau=0.005, policy_noise=0.2, noise_clip=0.5, policy_freq=2):\n",
    "\n",
    "        for it in range(iterations):\n",
    "\n",
    "            # Step 4: We sample a batch of transitions (s, s’, a, r) from the memory\n",
    "            batch_states, batch_next_states, batch_actions, batch_rewards, batch_dones = replay_buffer.sample(batch_size)\n",
    "            state = torch.Tensor(batch_states).to(device)\n",
    "            next_state = torch.Tensor(batch_next_states).to(device)\n",
    "            action = torch.Tensor(batch_actions).to(device)\n",
    "            reward = torch.Tensor(batch_rewards).to(device)\n",
    "            done = torch.Tensor(batch_dones).to(device)\n",
    "\n",
    "            # Step 5: From the next state s’, the Actor target plays the next action a’\n",
    "            next_action = self.actor_target(next_state)\n",
    "\n",
    "            # Step 6: We add Gaussian noise to this next action a’ and we clamp it in a range of values supported by the environment\n",
    "            noise = torch.Tensor(batch_actions).data.normal_(0, policy_noise).to(device)\n",
    "            noise = noise.clamp(-noise_clip, noise_clip)\n",
    "            next_action = (next_action + noise).clamp(-self.max_action, self.max_action)\n",
    "\n",
    "            # Step 7: The two Critic targets take each the couple (s’, a’) as input and return two Q-values Qt1(s’,a’) and Qt2(s’,a’) as outputs\n",
    "            target_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
    "\n",
    "            # Step 8: We keep the minimum of these two Q-values: min(Qt1, Qt2)\n",
    "            target_Q = torch.min(target_Q1, target_Q2)\n",
    "\n",
    "            # Step 9: We get the final target of the two Critic models, which is: Qt = r + γ * min(Qt1, Qt2), where γ is the discount factor\n",
    "            target_Q = reward + ((1 - done) * discount * target_Q).detach()\n",
    "\n",
    "            # Step 10: The two Critic models take each the couple (s, a) as input and return two Q-values Q1(s,a) and Q2(s,a) as outputs\n",
    "            current_Q1, current_Q2 = self.critic(state, action)\n",
    "\n",
    "            # Step 11: We compute the loss coming from the two Critic models: Critic Loss = MSE_Loss(Q1(s,a), Qt) + MSE_Loss(Q2(s,a), Qt)\n",
    "            critic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q)\n",
    "\n",
    "            # Step 12: We backpropagate this Critic loss and update the parameters of the two Critic models with a SGD optimizer\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "            # Step 13: Once every two iterations, we update our Actor model by performing gradient ascent on the output of the first Critic model\n",
    "            if it % policy_freq == 0:\n",
    "                actor_loss = -self.critic.Q1(state, self.actor(state)).mean() # self.actor(state) -> action actor_loss -> score of the action\n",
    "                self.actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                self.actor_optimizer.step()\n",
    "\n",
    "                # Step 14: Still once every two iterations, we update the weights of the Actor target by polyak averaging\n",
    "                for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "                    target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "\n",
    "                # Step 15: Still once every two iterations, we update the weights of the Critic target by polyak averaging\n",
    "                for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "                    target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "\n",
    "    # Making a save method to save a trained model\n",
    "    def save(self, filename, directory):\n",
    "        torch.save(self.actor.state_dict(), '%s/%s_actor.pth' % (directory, filename))\n",
    "        torch.save(self.critic.state_dict(), '%s/%s_critic.pth' % (directory, filename))\n",
    "\n",
    "    # Making a load method to load a pre-trained model\n",
    "    def load(self, filename, directory):\n",
    "        self.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, filename)))\n",
    "        self.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ka-ZRtQvjBex"
   },
   "source": [
    "## We make a function that evaluates the policy by calculating its average reward over 10 episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qabqiYdp9wDM"
   },
   "outputs": [],
   "source": [
    "def evaluate_policy(policy, eval_episodes=10):\n",
    "    avg_reward = 0.\n",
    "    action_arr = []\n",
    "    for _ in range(eval_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = policy.select_action(np.array(obs))\n",
    "            action_arr.append(action)\n",
    "            obs, reward, done, _ = env.step(action)\n",
    "            avg_reward += reward\n",
    "    avg_reward /= eval_episodes\n",
    "    print(\"%2f, \" %(float(sum(action_arr)/len(action_arr))))\n",
    "    print(\"\\n\")\n",
    "    print (\"---------------------------------------\")\n",
    "    print (\"Average Reward over the Evaluation Step: %f\" % (avg_reward))\n",
    "    print (\"---------------------------------------\")\n",
    "    return avg_reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGuKmH_ijf7U"
   },
   "source": [
    "## We set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFj6wbAo97lk"
   },
   "outputs": [],
   "source": [
    "env_name = \"SALL_ENV\" # Name of a environment (set it to any Continous environment you want)\n",
    "seed = 0 # Random seed number\n",
    "start_timesteps = 1e4 # Number of iterations/timesteps before which the model randomly chooses an action, and after which it starts to use the policy network\n",
    "eval_freq = 5e3 # How often the evaluation step is performed (after how many timesteps)\n",
    "max_timesteps = 3e4 # Total number of iterations/timesteps\n",
    "save_models = False # Boolean checker whether or not to save the pre-trained model\n",
    "expl_noise = 0.1 # Exploration noise - STD value of exploration Gaussian noise\n",
    "batch_size = 100 # Size of the batch\n",
    "discount = 0.99 # Discount factor gamma, used in the calculation of the total discounted reward\n",
    "tau = 0.005 # Target network update rate\n",
    "policy_noise = 0.2 # STD of Gaussian noise added to the actions for the exploration purposes\n",
    "noise_clip = 0.5 # Maximum value of the Gaussian noise added to the actions (policy)\n",
    "policy_freq = 2 # Number of iterations to wait before the policy network (Actor model) is updated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hjwf2HCol3XP"
   },
   "source": [
    "## We create a file name for the two saved models: the Actor and Critic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1fyH8N5z-o3o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Settings: TD3_SALL_ENV(seed:0)\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "file_name = \"%s_%s(seed:%s)\" % (\"TD3\", env_name, str(seed))\n",
    "print (\"---------------------------------------\")\n",
    "print (\"Settings: %s\" % (file_name))\n",
    "print (\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kop-C96Aml8O"
   },
   "source": [
    "## We create a folder inside which will be saved the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Src07lvY-zXb"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../Model_Repository/results\"):\n",
    "    os.makedirs(\"../Model_Repository/results\")\n",
    "if save_models and not os.path.exists(\"../Model_Repository/pytorch_models\"):\n",
    "    os.makedirs(\"../Model_Repository/pytorch_models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEAzOd47mv1Z"
   },
   "source": [
    "## We create the PyBullet environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CyQXJUIs-6BV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oreo/opt/anaconda3/envs/RL_env/lib/python3.7/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = Enviorment_Setting.ETFenv(id = \"0051\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5YdPG4HXnNsh"
   },
   "source": [
    "## We set seeds and we get the necessary information on the states and actions in the chosen environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z3RufYec_ADj"
   },
   "outputs": [],
   "source": [
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "state_dim = len(env.observation_space)\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HWEgDAQxnbem"
   },
   "source": [
    "## We create the policy network (the Actor model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wTVvG7F8_EWg"
   },
   "outputs": [],
   "source": [
    "policy = TD3(state_dim, action_dim, max_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZI60VN2Unklh"
   },
   "source": [
    "## We create the Experience Replay memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sd-ZsdXR_LgV"
   },
   "outputs": [],
   "source": [
    "replay_buffer = ReplayBuffer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QYOpCyiDnw7s"
   },
   "source": [
    "## We define a list where all the evaluation results over 10 episodes are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhC_5XJ__Orp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.007625, \n",
      "\n",
      "\n",
      "---------------------------------------\n",
      "Average Reward over the Evaluation Step: -84.169615\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "evaluations = [evaluate_policy(policy)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xm-4b3p6rglE"
   },
   "source": [
    "## We create a new folder directory in which the final results (videos of the agent) will be populated"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MTL9uMd0ru03"
   },
   "source": [
    "def mkdir(base, name):\n",
    "    path = os.path.join(base, name)\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "work_dir = mkdir('exp', 'brs')\n",
    "monitor_dir = mkdir(work_dir, 'monitor')\n",
    "max_episode_steps = env._max_episode_steps\n",
    "save_env_vid = False\n",
    "if save_env_vid:\n",
    "  env = wrappers.Monitor(env, monitor_dir, force = True)\n",
    "  env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "31n5eb03p-Fm"
   },
   "source": [
    "## We initialize the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1vN5EvxK_QhT"
   },
   "outputs": [],
   "source": [
    "total_timesteps = 0\n",
    "timesteps_since_eval = 0\n",
    "episode_num = 0\n",
    "done = True\n",
    "t0 = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actions_Scale(gym.ActionWrapper):\n",
    "    def __init__(self, env, low_, high_):\n",
    "        super().__init__(env)\n",
    "        self.action_space = Box(low = low_, high= high_, shape=(1,), dtype=np.int)\n",
    "    def action(self,act):\n",
    "        return act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q9gsjvtPqLgT"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y_ouY4NH_Y0I",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Timesteps: 100 Episode Num: 1 Reward: -451.6185088523273\n",
      "Total Timesteps: 200 Episode Num: 2 Reward: -239.6358985789817\n",
      "Total Timesteps: 300 Episode Num: 3 Reward: -10095.588108124215\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wm/t689898n3nzdxzs3f09sjklr0000gn/T/ipykernel_19696/792373822.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_timesteps\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total Timesteps: {} Episode Num: {} Reward: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_timesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_noise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_clip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# We evaluate the episode and we save the policy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wm/t689898n3nzdxzs3f09sjklr0000gn/T/ipykernel_19696/1257546005.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, replay_buffer, iterations, batch_size, discount, tau, policy_noise, noise_clip, policy_freq)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Step 4: We sample a batch of transitions (s, s’, a, r) from the memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mbatch_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_next_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dones\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_next_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wm/t689898n3nzdxzs3f09sjklr0000gn/T/ipykernel_19696/2851075334.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mbatch_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mbatch_next_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mbatch_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mbatch_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mbatch_dones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# We start the main loop over 500,000 timesteps\n",
    "max_episode_steps = env._max_episode_steps\n",
    "env_og = env\n",
    "while total_timesteps < max_timesteps:\n",
    "  \n",
    "    # If the episode is done\n",
    "    if done:\n",
    "\n",
    "        # If we are not at the very beginning, we start the training process of the model\n",
    "        if total_timesteps != 0:\n",
    "            print(\"Total Timesteps: {} Episode Num: {} Reward: {}\".format(total_timesteps, episode_num, episode_reward))\n",
    "            policy.train(replay_buffer, episode_timesteps, batch_size, discount, tau, policy_noise, noise_clip, policy_freq)\n",
    "\n",
    "        # We evaluate the episode and we save the policy\n",
    "        if timesteps_since_eval >= eval_freq:\n",
    "            timesteps_since_eval %= eval_freq\n",
    "            evaluations.append(evaluate_policy(policy))\n",
    "            policy.save(file_name, directory=\"../Model_Repository/pytorch_models\")\n",
    "            np.save(\"../Model_Repository/results/%s\" % (file_name), evaluations)\n",
    "\n",
    "        # When the training step is done, we reset the state of the environment\n",
    "        obs = env.reset()\n",
    "\n",
    "        # Set the Done to False\n",
    "        done = False\n",
    "\n",
    "        # Set rewards and episode timesteps to zero\n",
    "        episode_reward = 0\n",
    "        episode_timesteps = 0\n",
    "        episode_num += 1\n",
    "\n",
    "    # Before 10000 timesteps, we play random actions\n",
    "    if total_timesteps < start_timesteps:\n",
    "        action = env.action_space.sample()\n",
    "    else: # After 10000 timesteps, we switch to the model\n",
    "        # 這邊加 wrapper autoscale action\n",
    "        action = policy.select_action(np.array(obs))\n",
    "    # If the explore_noise parameter is not 0, we add noise to the action and we clip it\n",
    "        if expl_noise != 0:\n",
    "            action = (action + np.random.normal(0, expl_noise, size=env.action_space.shape[0])).clip(env.action_space.low, env.action_space.high)\n",
    "    # The agent performs the action in the environment, then reaches the next state and receives the reward\n",
    "    new_obs, reward, done, _ = env.step(action)\n",
    "    # We check if the episode is done\n",
    "    done_bool = 0 if episode_timesteps + 1 == max_episode_steps else float(done)\n",
    "\n",
    "    # We increase the total reward\n",
    "    episode_reward += reward\n",
    "\n",
    "    # We store the new transition into the Experience Replay memory (ReplayBuffer)\n",
    "    replay_buffer.add((obs, new_obs, action, reward, done_bool))\n",
    "\n",
    "    # We update the state, the episode timestep, the total timesteps, and the timesteps since the evaluation of the policy\n",
    "    obs = new_obs\n",
    "    episode_timesteps += 1\n",
    "    total_timesteps += 1\n",
    "    timesteps_since_eval += 1\n",
    "\n",
    "# We add the last policy evaluation to our list of evaluations and we save our model\n",
    "evaluations.append(evaluate_policy(policy))\n",
    "if save_models: policy.save(\"%s\" % (file_name), directory=\"../Model_Repository/pytorch_models\")\n",
    "np.save(\"../Model_Repository/results/%s\" % (file_name), evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wi6e2-_pu05e"
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oW4d1YAMqif1"
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "  \n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        super(Actor, self).__init__()\n",
    "        self.layer_1 = nn.Linear(state_dim, 400)\n",
    "        self.layer_2 = nn.Linear(400, 300)\n",
    "        self.layer_3 = nn.Linear(300, action_dim)\n",
    "        self.max_action = max_action\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer_1(x))\n",
    "        x = F.relu(self.layer_2(x))\n",
    "        x = self.max_action * torch.tanh(self.layer_3(x)) \n",
    "        return x\n",
    "\n",
    "class Critic(nn.Module):\n",
    "  \n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(Critic, self).__init__()\n",
    "        # Defining the first Critic neural network\n",
    "        self.layer_1 = nn.Linear(state_dim + action_dim, 400)\n",
    "        self.layer_2 = nn.Linear(400, 300)\n",
    "        self.layer_3 = nn.Linear(300, 1)\n",
    "        # Defining the second Critic neural network\n",
    "        self.layer_4 = nn.Linear(state_dim + action_dim, 400)\n",
    "        self.layer_5 = nn.Linear(400, 300)\n",
    "        self.layer_6 = nn.Linear(300, 1)\n",
    "\n",
    "    def forward(self, x, u):\n",
    "        xu = torch.cat([x, u], 1)\n",
    "        # Forward-Propagation on the first Critic Neural Network\n",
    "        x1 = F.relu(self.layer_1(xu))\n",
    "        x1 = F.relu(self.layer_2(x1))\n",
    "        x1 = self.layer_3(x1)\n",
    "        # Forward-Propagation on the second Critic Neural Network\n",
    "        x2 = F.relu(self.layer_4(xu))\n",
    "        x2 = F.relu(self.layer_5(x2))\n",
    "        x2 = self.layer_6(x2)\n",
    "        return x1, x2\n",
    "\n",
    "    def Q1(self, x, u):\n",
    "        xu = torch.cat([x, u], 1)\n",
    "        x1 = F.relu(self.layer_1(xu))\n",
    "        x1 = F.relu(self.layer_2(x1))\n",
    "        x1 = self.layer_3(x1)\n",
    "        return x1\n",
    "\n",
    "# Selecting the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Building the whole Training Process into a class\n",
    "\n",
    "class TD3(object):\n",
    "  \n",
    "    def __init__(self, state_dim, action_dim, max_action):\n",
    "        self.actor = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        self.actor_target = Actor(state_dim, action_dim, max_action).to(device)\n",
    "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
    "        self.actor_optimizer = torch.optim.Adam(self.actor.parameters())\n",
    "        self.critic = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_target = Critic(state_dim, action_dim).to(device)\n",
    "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
    "        self.critic_optimizer = torch.optim.Adam(self.critic.parameters())\n",
    "        self.max_action = max_action\n",
    "\n",
    "    def select_action(self, state):\n",
    "        state = torch.Tensor(state.reshape(1, -1)).to(device)\n",
    "        return self.actor(state).cpu().data.numpy().flatten()\n",
    "\n",
    "    def train(self, replay_buffer, iterations, batch_size=100, discount=0.99, tau=0.005, policy_noise=0.2, noise_clip=0.5, policy_freq=2):\n",
    "    \n",
    "        for it in range(iterations):\n",
    "      \n",
    "            # Step 4: We sample a batch of transitions (s, s’, a, r) from the memory\n",
    "            batch_states, batch_next_states, batch_actions, batch_rewards, batch_dones = replay_buffer.sample(batch_size)\n",
    "            state = torch.Tensor(batch_states).to(device)\n",
    "            next_state = torch.Tensor(batch_next_states).to(device)\n",
    "            action = torch.Tensor(batch_actions).to(device)\n",
    "            reward = torch.Tensor(batch_rewards).to(device)\n",
    "            done = torch.Tensor(batch_dones).to(device)\n",
    "      \n",
    "            # Step 5: From the next state s’, the Actor target plays the next action a’\n",
    "            next_action = self.actor_target(next_state)\n",
    "      \n",
    "            # Step 6: We add Gaussian noise to this next action a’ and we clamp it in a range of values supported by the environment\n",
    "            noise = torch.Tensor(batch_actions).data.normal_(0, policy_noise).to(device)\n",
    "            noise = noise.clamp(-noise_clip, noise_clip)\n",
    "            next_action = (next_action + noise).clamp(-self.max_action, self.max_action)\n",
    "\n",
    "            # Step 7: The two Critic targets take each the couple (s’, a’) as input and return two Q-values Qt1(s’,a’) and Qt2(s’,a’) as outputs\n",
    "            target_Q1, target_Q2 = self.critic_target(next_state, next_action)\n",
    "\n",
    "            # Step 8: We keep the minimum of these two Q-values: min(Qt1, Qt2)\n",
    "            target_Q = torch.min(target_Q1, target_Q2)\n",
    "\n",
    "            # Step 9: We get the final target of the two Critic models, which is: Qt = r + γ * min(Qt1, Qt2), where γ is the discount factor\n",
    "            target_Q = reward + ((1 - done) * discount * target_Q).detach()\n",
    "\n",
    "            # Step 10: The two Critic models take each the couple (s, a) as input and return two Q-values Q1(s,a) and Q2(s,a) as outputs\n",
    "            current_Q1, current_Q2 = self.critic(state, action)\n",
    "\n",
    "            # Step 11: We compute the loss coming from the two Critic models: Critic Loss = MSE_Loss(Q1(s,a), Qt) + MSE_Loss(Q2(s,a), Qt)\n",
    "            critic_loss = F.mse_loss(current_Q1, target_Q) + F.mse_loss(current_Q2, target_Q)\n",
    "\n",
    "            # Step 12: We backpropagate this Critic loss and update the parameters of the two Critic models with a SGD optimizer\n",
    "            self.critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            self.critic_optimizer.step()\n",
    "\n",
    "            # Step 13: Once every two iterations, we update our Actor model by performing gradient ascent on the output of the first Critic model\n",
    "            if it % policy_freq == 0:\n",
    "                actor_loss = -self.critic.Q1(state, self.actor(state)).mean()\n",
    "                self.actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                self.actor_optimizer.step()\n",
    "        \n",
    "            # Step 14: Still once every two iterations, we update the weights of the Actor target by polyak averaging\n",
    "            for param, target_param in zip(self.critic.parameters(), self.critic_target.parameters()):\n",
    "                target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "        \n",
    "            # Step 15: Still once every two iterations, we update the weights of the Critic target by polyak averaging\n",
    "            for param, target_param in zip(self.actor.parameters(), self.actor_target.parameters()):\n",
    "                target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "  \n",
    "    # Making a save method to save a trained model\n",
    "    def save(self, filename, directory):\n",
    "        torch.save(self.actor.state_dict(), '%s/%s_actor.pth' % (directory, filename))\n",
    "        torch.save(self.critic.state_dict(), '%s/%s_critic.pth' % (directory, filename))\n",
    "  \n",
    "    # Making a load method to load a pre-trained model\n",
    "    def load(self, filename, directory):\n",
    "        self.actor.load_state_dict(torch.load('%s/%s_actor.pth' % (directory, filename)))\n",
    "        self.critic.load_state_dict(torch.load('%s/%s_critic.pth' % (directory, filename)))\n",
    "\n",
    "def evaluate_policy(policy, eval_episodes=10):\n",
    "    avg_reward = 0.\n",
    "    for _ in range(eval_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "    while not done:\n",
    "        action = policy.select_action(np.array(obs))\n",
    "        obs, reward, done, _ = env.step(action)\n",
    "        avg_reward += reward\n",
    "    avg_reward /= eval_episodes\n",
    "    print (\"---------------------------------------\")\n",
    "    print (\"Average Reward over the Evaluation Step: %f\" % (avg_reward))\n",
    "    print (\"---------------------------------------\")\n",
    "    return avg_reward\n",
    "\n",
    "env_name = \"SALL_ENV\"\n",
    "seed = 0\n",
    "\n",
    "file_name = \"%s_%s(seed:%s)\" % (\"TD3\", env_name, str(seed))\n",
    "print (\"---------------------------------------\")\n",
    "print (\"Settings: %s\" % (file_name))\n",
    "print (\"---------------------------------------\")\n",
    "\n",
    "import Enviorment_Setting\n",
    "\n",
    "\n",
    "eval_episodes = 10\n",
    "save_env_vid = True\n",
    "env = Enviorment_Setting.ETFenv(id = \"0050\")\n",
    "max_episode_steps = env._max_episode_steps\n",
    "\n",
    "env.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "state_dim = len(env.observation_space)\n",
    "action_dim = env.action_space.shape[0]\n",
    "max_action = float(env.action_space.high[0])\n",
    "policy = TD3(state_dim, action_dim, max_action)\n",
    "policy.load(file_name, '../Model_Repository/pytorch_models')\n",
    "_ = evaluate_policy(policy, eval_episodes=eval_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "id = \"0050\"\n",
    "test_address = \"../File_Repository/Test set/\" + id + \"_test.csv\"\n",
    "train_address = \"../File_Repository/Train set/\" + id + \"_train.csv\"\n",
    "test_dataset = pd.read_csv(test_address)\n",
    "train_dataset = pd.read_csv(train_address)\n",
    "\n",
    "X_train = train_dataset.iloc[:, 1:].values\n",
    "X_test = test_dataset.iloc[:, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ema(prices, days, smoothing=2):\n",
    "    ema = [sum(prices[:days]) / days]\n",
    "    for price in prices[days:]:\n",
    "        ema.append((price * (smoothing / (1 + days))) + ema[-1] * (1 - (smoothing / (1 + days))))\n",
    "    return ema\n",
    "\n",
    "def MACD(list_input):\n",
    "    prices = list_input[:,0]\n",
    "    ema_short = calculate_ema(prices, 12)\n",
    "    ema_long = calculate_ema(prices, 26)\n",
    "    len(ema_short)\n",
    "    dif = []\n",
    "    for i in range(0,len(prices)-len(ema_short)):\n",
    "        tmp = ema_short[i]\n",
    "        ema_short.insert( i, tmp)\n",
    "    \n",
    "    for j in range(0,len(prices)-len(ema_long)):\n",
    "        tmp = ema_long[i]\n",
    "        ema_long.insert( i, tmp)\n",
    "\n",
    "    for k in range(0,len(prices)):\n",
    "        dif.append(ema_short[k] - ema_long[k])\n",
    "\n",
    "    MACD = calculate_ema(dif, 9)\n",
    "    for j in range(0,len(prices)-len(MACD)):\n",
    "        tmp = MACD[i]\n",
    "        MACD.insert( i, tmp)\n",
    "\n",
    "    MACD_arr = np.array(MACD).reshape(len(MACD),1)\n",
    "    list_input = np.hstack((list_input,MACD_arr))\n",
    "    return list_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = MACD(list_input = X_train)\n",
    "X_test = MACD(list_input = X_test)\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "action = policy.select_action(np.array(X_test[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57310924, 0.08569278, 0.56484642, 0.56208054, 0.69506877,\n",
       "       0.11461227, 0.        , 0.05027933, 0.39458652])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8L0lEQVR4nO3dd3Rb5fnA8a+2ZMuW997OcvbegYQRCOPHKoRVCITVsgOUhl1KGwplr7ZAGC17QwkjjCxC9iB7ee+tZVmypPv7I43B2HHsRLY8ns85Ogfd+957n3tlokfvVCmKoiCEEEIIESTqYAcghBBCiP5NkhEhhBBCBJUkI0IIIYQIKklGhBBCCBFUkowIIYQQIqgkGRFCCCFEUEkyIoQQQoigkmRECCGEEEGlDXYAHeH3+yktLSUsLAyVShXscIQQQgjRAYqiYLfbSUpKQq0+fP1Hr0hGSktLSU1NDXYYQgghhDgKRUVFpKSkHHZ/r0hGwsLCgIM3Ex4eHuRohBBCCNERNpuN1NTU5u/xw+kVycihppnw8HBJRoQQQohe5khdLKQDqxBCCCGCSpIRIYQQQgSVJCNCCCGECKpe0WekIxRFwev14vP5gh2K6GIajQatVivDvIUQoo/oE8mIx+OhrKyMhoaGYIciuklISAiJiYno9fpghyKEEOIY9fpkxO/3k5eXh0ajISkpCb1eL7+Y+zBFUfB4PFRVVZGXl8fAgQPbnUhHCCFEz9frkxGPx4Pf7yc1NZWQkJBghyO6gclkQqfTUVBQgMfjwWg0BjskIYQQx6DP/KSUX8f9i3zeQgjRd8i/6EIIIYQIKklGepn8/HxUKhVbtmwJdihd6oEHHmD06NHBDkMIIUQ3kGSkl0lNTaWsrIzhw4d32TVmzpzJLbfc0mXnF0IIIX5JkpFexOPxoNFoSEhIQKsNbt/jQ/O6CCGE6JnqrU389+sytu2yBjuUI5JkJEhmzpzJDTfcwA033EBERATR0dHcc889KIrSXCYjI4OHHnqIefPmYbFYuPrqq9tsptmxYwenn3464eHhhIWFMWPGDA4cONC8/5VXXiEnJwej0ciQIUN4/vnnDxvXvHnzWL58OU899RQqlQqVSkV+fj7Lli1DpVLx1VdfMX78eAwGAytXrkRRFB555BGysrIwmUyMGjWK999/v/l8h4779ttvGT9+PCEhIUydOpU9e/a0uO7DDz9MfHw8YWFhzJ8/n8bGxgA8ZSGE6J/cHj9XLdjIw8/s5Xd/2MKqtdXBDqldkowE0WuvvYZWq2Xt2rU8/fTTPPHEE7z00kstyjz66KMMHz6cjRs3cu+997Y6R0lJCccddxxGo5HvvvuOjRs3cuWVVzbXWrz44ovcfffd/OUvf2HXrl389a9/5d577+W1115rM6annnqKKVOmcPXVV1NWVkZZWRmpqanN+//whz+waNEidu3axciRI7nnnnt45ZVXeOGFF9ixYwe33norl156KcuXL29x3rvvvpvHHnuMDRs2oNVqufLKK5v3vfvuu9x///385S9/YcOGDSQmJrabMAkhhGhfabmL8spGhmbsRqf1sm5zXbBDap/SC1itVgVQrFZrq30ul0vZuXOn4nK5ghDZ0Tv++OOVnJwcxe/3N2+78847lZycnOb36enpytlnn93iuLy8PAVQNm/erCiKoixcuFDJzMxUPB5Pm9dJTU1V3nzzzRbb/vznPytTpkxpN7abb765xbbvv/9eAZSPP/64eZvD4VCMRqOyevXqFmXnz5+vXHTRRS2O++abb5r3f/755wrQ/JlNmTJFue6661qcY9KkScqoUaMOG2Nv/dyFEKKrlVW4lH++lqtc8ft3lIV3/0U5+TdLlB831AQllva+v3+p1096djj//e9/sdvt3Xa9sLAwzjjjjE4dM3ny5BazxU6ZMoXHHnsMn8+HRqMBYPz48e2eY8uWLcyYMQOdTtdqX1VVFUVFRcyfP5+rr766ebvX68VisXQq1kN+Gc/OnTtpbGzk5JNPblHG4/EwZsyYFttGjhzZ/N+JiYkAVFZWkpaWxq5du7juuutalJ8yZQrff//9UcUohBD9lden8Ps7t+BwWBmcWoEhZDAP3JbF5HFRwQ6tXX02GelsYtBThYaGtrvfZDIddp/f7wcONtVMmjSpxb5Dyc6xxHPo/J9//jnJycktyhkMhhbvf5ksHUrADh0vhBAiMBwOL5XVboakFbKvOJuoGIVIS8//t7bPJiO9wZo1a1q9HzhwYKcShZEjR/Laa6/R1NTUqnYkPj6e5ORkcnNzueSSSzp8Tr1e36HVj4cOHYrBYKCwsJDjjz++w+f/tZycHNasWcNll13WvO3Xz0YIIfobv1/hvU9L2L3fzmknxjNhzJFrNyzhWo6bHI29phGXJ5TxY8w4nc5uiPbYSDISREVFRSxYsIBrr72WTZs28cwzz/DYY4916hw33HADzzzzDBdeeCELFy7EYrGwZs0aJk6cyODBg3nggQe46aabCA8PZ86cObjdbjZs2EBdXR0LFixo85wZGRmsXbuW/Px8zGYzUVFt/w8QFhbG7bffzq233orf72f69OnYbDZWr16N2Wzm8ssv79A93HzzzVx++eWMHz+e6dOn88Ybb7Bjxw6ysrI69SyEEKIv+er7Cp55+QBqlZ/vVlXx7osTiY9tfy0ulUrF/bcP5t//2cK9d02myV3N/v37uynioyfJSBBddtlluFwuJk6ciEaj4cYbb+Saa67p1Dmio6P57rvvuOOOOzj++OPRaDSMHj2aadOmAXDVVVcREhLCo48+yh/+8AdCQ0MZMWJEu5Oa3X777Vx++eUMHToUl8tFXl7eYcv++c9/Ji4ujkWLFpGbm0tERARjx47lrrvu6vA9zJ07lwMHDnDnnXfS2NjIeeedx+9+9zu++uqrDp9DCCF6Ar9f4cvvKqip83D6SQlEReqP+lxllY1o1T6GZ+1ky/4R1NR5jpiMAFRVVTAgO4W4GAP19aG9omZEpSi/mNiih7LZbFgsFqxWK+Hh4S32NTY2kpeXR2ZmZq9avXXmzJmMHj2aJ598Mtih9Eq99XMXQvRtr75TwEv/yUelgrRkE/95fkKLgQqdUVHVyM13rSYtegOEnMaiu4eh0Rz5XOvWrSMyMpKBAwfi8Xj49NNP+c1vfnNUMRyr9r6/f0nmGRFCCCECYM9+Oyt+rCYltoTMxDwKil243R3rPFpX7+HblZUUljQ0b4uPNfLXhVlEhHt5+J6hHUpEAEpLS0lKSgIO9gFsamrq/M10M2mmEUIIIY7Rih+rueuvO4iNqCI2wo5e6+GE6bEYjUcekGBzNHH5jRuorW9Cq1Xxr7+PYVB2GABOpx2/34/H4+lwLbDT6TziSMyeRpKRIFm2bFmwQxBCCBEgq9ZWo9c2kRpXyuZ9I7hwThFXzx/YoWP37LNTW9/EwJQD7C/OYu2muuZkxG63k5CQgN1uP2IyoigKB/KsKL3wq12aaYQQQohjNGFMFEa9i3q7hZSkUIYOSaOysqJDxw7IMhMV4SM9vgiD3sOYERHN+2w2G8nJydhstiOe5+mXcrn13hV8vcLDstU/r0WjVqt7/LxOkowIIYQQx+jk4+O44cokTpiRxj8fHUNaWipFRUUdOjbSouemeQbMYfH86fY0hg/5uaOn3W7vUDLi9yt88HkpllAb9c5wPlxS2rzPZDLR0HCwL4rb7aMnjlvpM8lIT3y4ouvI5y2E6GliIn1Mm5xCeJiOlJQUSkpKOnxsZUUBp54yHZOhocV2r9dLVFTUEZc3UatVZKSaiA6vxWqPYGCmuXlfaGgoVqudBff9xIm/WcW1t2/G2eDt3M11sV6fjByadfRQ1if6h0Ofd1tr8gghRDDY7fbm4asGgwG3233EY3butfHIM1uoqlWIi4ujpqamxX5FUQgPD+9QM80ffx9LSkoiv7sim+suy2jeHhoayqatFazbXEdsRBW79lr5bmVV526ui/W+Xi6/otFoiIiIoLKyEoCQkJCjHtMtej5FUWhoaKCyspKIiIijXmNHCCECzWazNScjeYVONm/3sOR3y7j56pFMHNtyJuvPvynnxX/nUVPnITWuGFejkYxsD257XXMZRVFQqVSYzWYcDke71y6vbGT3rp+4/OLjiYuLa7EvNDSUepsLlcrPoJQDxFhqef4VHbmFTm6cn41aHfzvzF6fjAAkJCQANCckou+LiIho/tyFEKIncLlczSNenvzXfsrLTXh9VTz42G7++8bU5nI2RxN/e3oPoSY7wzKKUKsUSqsTKS5zE2X6eV2wQ0N01Wp1u03Tb3xQyD9f28+oAfkYwydw2kkt94eGhhIR7uT6eZGsWZuKs9FPTHgu733qY/K4KCaNDf6Kvn0iGVGpVCQmJhIXF9crJncRx0an00mNiBCiRzpUM69Wqah3WkiJKaHS1nJVcxUqUMGA5Fx25g/B3WQgzKzl9JMTWPODCr/fj1qtblHT0p433i8ixlJLVX00b35YxGkntfyhFhp6cEr41Hgfumk5PPGijdEDfvpfnAG68WPUJ5KRQzQajXxJCSGE6Ha/rrm45ZoBPPREE5HGPH53bQ5+v8LWHVaMBjU5g8K5aX40y1eEM2JYPNdcmklmeigmo4Zd/5s6PTIyEpvNRljYwflG1Go1Xq8Xrbb113ZGWgiOeie11ijGDm492dmhZKS6upr/O+scDhTmU1G0gwvPSWH86MiueSCd1KeSESGEECIY3G53i0nJ0lNDePHxcXzwQT7DBhl57IV9fPJlGQA3zs8m3FDEPXfMIT4+vsV5oqOjqampITIyErvdTkREBHBwlXSHw9H8/pf+ctcw/vXSTiJjsrn0/EGt9oeEhOB0OvH7/ZiMev5wwyDeemsjF12UHbgHcIx6/WgaIYQQIth+WYvxS6mpB+cb+er7CuIjK0iNLeZfr+9j5Y/5KCpLq/KHkpFD5zzUTNPeiJpIi570ZA1X/XYIISFt1TGoKCuvJCa2ZcfWnjRFQqeTkRUrVnDmmWeSlJSESqXi448/brf8qlWrmDZtGtHR0ZhMJoYMGcITTzxxtPEKIYQQPc4vh/X+Unp6OgUFBYwaFk5ybBlqtcLoAZvIK7Hwj9dyW5V3uUNYt7GQ3AIndru9OcEJCwtrd3ivoiio1a2/0r1ePzfetZWyCg///sBFWUUjcHABPY/Hc7S3G3CdTkacTiejRo3i2Wef7VD50NBQbrjhBlasWMGuXbu45557uOeee/jXv/7V6WCFEEKInuhwnU3j4uKorKzksvO0DBs6iJLqNHbkD6GsNgGfr2XZkjIXN9+7jz37Kph30wbWbSpn2Y9WPE1+vv/Rydsf7mX9lrpW12jPjj12tu6w0tBoorgilK++PzhFfU9LRjrdZ2TOnDnMmTOnw+XHjBnDmDFjmt9nZGTw4YcfsnLlSq655prOXl4IIYToEWrqPOQWOBk66GCtRWxsbKsyazfVsXaTjQ1bv+Wcc37D/UN0PPvyAVIj9Vw3L7NF2R17bLg9Cj6/mgFJ+3E63fz1yb3s2efgy2+tJMfW8YcHt/HJ61MIN/884aPH4znsBJAJcQY0GhXb8obj96tITTYBP0/K1lbTUjB0ewfWzZs3s3r1ah566KHDlnG73S1mruvIzHNCCCFEdyksaWD+LZtwNfpIiDNwyZlWxrRRM/LUi/tRecMw6t08u7iId1+cxKxprZMWgDEjIggza9mWOwyzyU6o82CiUF7ViLvJgEnfSFOTgtPpa5GMtDcEOD7WyJN/HsnXyysZOjCME6YfvHZHZ4jtLt2WjKSkpFBVVYXX6+WBBx7gqquuOmzZRYsW8ac//am7QhNCCCE6ZdXaGjweN4NS8tlbnE15eT1ms7lVuTCzlr37k0AF2entf+XGRhv493PjWb+5jrc+Kia3wMmksZH8bl4W+3KdqNV+zj09kcR4Y4vjrFZru/ORjBkR0WIlYOgDzTRHa+XKlTgcDtasWcMf//hHBgwYwEUXXdRm2YULF7JgwYLm9zabjdTU1O4KVQghhDiswhIXVpuXQakHUKkUMhJLcTR4qbN6iY7Utyh774IhPPPiAfzATfOPPJQ2JsrAnBMTOPWEeNxuP0bjwbmz3n95EkuW1DJ5cuvZUm02GxZL65E57em3NSOZmQfbxkaMGEFFRQUPPPDAYZMRg8GAwWDortCEEEKIDikuc3HV7VsxG6qIDtcRlzCB+qplFJX4mH/LRt78x0RCTD9PvpmaFMIj94/o9HVUKlVzIgL/W5U3I43i4mJiYmJalLXZbK3WozmSnpaMBGWeEUVRetRDEEIIITpi2247niaF1JgCDpQNwN0Ee4sHUG+PoLrWQ2Fx160gn5KSQlFRUavtHZ02/pcMBkPvbqZxOBzs37+/+X1eXh5btmwhKiqKtLQ0Fi5cSElJCa+//joAzz33HGlpaQwZMgQ4OO/I3//+d2688cYA3YIQQgjRPUYPDcdkVONX1BiNek49MZ61G2vILcsgIc5ARmpIl13bYrG0OaDj0IJ6naHX63tUpUCnk5ENGzYwa9as5veH+nZcfvnlvPrqq5SVlVFYWNi83+/3s3DhQvLy8tBqtWRnZ/Pwww9z7bXXBiB8IYQQovskxht55YnRvPfubu7542jiYw1kpo4nr9DJhNGRLZpWAk2lUqHV6qiqdhAb83Nn2cNNeNaentZM0+lkZObMme1OIfvqq6+2eH/jjTdKLYgQQog+IyZSQ3ysifjYg30bs9JDyUrvXM3E0di518aXy5t445OlnHrySH5/xdGvLdPTkhFZm0YIIYToBI/HE5RBFu98XExVXRgWs403PyzG2eDF7Xaj1+uPfPCv9LShvZKMCCGEEJ3gdruDkozExxpocJsIMTQSHqZl7wE7V9y4km9X2Vm3qbZT5+ppHVglGRFCCCE6obGxMSjJyPyLM7jgrCyS4tU89dAonn7xAE6nnXqbjkee29upc2k0Gny/XhwniCQZEUIIITohWDUjBoOG6y7PZlC2mYFZZgwGDSZDI41NBvT63v113rujF0IIIbpZsJKRX/vjTYNIS4akxGjuvy0n2OEck25fKE8IIYTozYKdjBzqfJqRGsqUsUZOPXUyJpMpaPEEgtSMCCGEEJ3gdrsxGo1HLthFwsLCmic/a2xsDGosgSLJiBBCCNEJwa4ZCQ8PbzETq0qlOupztTdvWHeSZEQIIYTohGAnI2FhYdjtdvx+/zElIjqdjqampgBGdvQkGRFCCCE6IdjJyKGaEbvdTlhY2FGfpyfNwirJiBBCCNEJPSUZqa+vx2KxHPV5etIsrJKMCCGEEJ1wtFOwB4rZbMbhcGC1WomIiDjq80jNiBBCCNFLHc0quYGk0Wjw+/3U19dLMiKEEEKI4LFardJMI4QQQojgUKvV2Gw2zGbzUZ9DakaEEEIIcdQO9Rs5lqG9kowIIYQQ4qgZDKFotcc2okeSESGEEKIX8nq9aDSaoMawal01L75ZwdrNbl5+M/+ozyN9RoQQQoheKNhzjAC89WExTpeRBreJ198tPOop3aVmRAghhOiFekIykpZiwuqMoLAyjZRE41H3G3E4obTcToPLF+AIO08b7ACEEEKI3qInJCM3XTWAmEgDdoeXC89JOapz5BY4ufb2nxiYVMXSNRt55alxmIzBa36SZEQIIYTooJ6QjJiMGuZfknFM51ixpppGN6jVCsWlLnbtszN2RERA4jsa0kwjhBBCdJDb7cZoNAY7jGM2bHA4h7qamIwaMlJCghqPJCNCCCFEB/WEmpFAmDA6kicfGkl6SggvPT6WqMjgrbUDkowIIYQQHdZXkhGA8aMiSUkykZ4a3FoRkGRECCGE6LC+lIz0JJKMCCGEEB3U2NgoyUgXkGRECCGE6CCpGekakowIIYQQHeTxeCQZ6QKSjAghhBBHoPj91L39ItaNP2J75Qn8np4xjXpfIcmIEEIIcQTu/btwrvoaxe/Ds2MTDetWBDukgDnatW0CSZIRIYQQ4ghU+oPzcBz62lbpgjsvR6BotVq8Xm+ww+h8MrJixQrOPPNMkpKSUKlUfPzxx+2W//DDDzn55JOJjY0lPDycKVOm8NVXXx1tvEIIIUS3M2QMxHL2paiNJkKPn0PI+OnBDikgtFotPl/wF8rrdDLidDoZNWoUzz77bIfKr1ixgpNPPpklS5awceNGZs2axZlnnsnmzZs7HawQQggRLKaZpxOaM4rI869EpQneonKB1FNqRjq9UN6cOXOYM2dOh8s/+eSTLd7/9a9/5ZNPPuGzzz5jzJgxnb28EEIIERR2ux2z2RzsMAKq1yYjx8rv92O324mKijpsGbfbjdv9c09lm83WHaEJIYQQh+VwOCQZ6SLd3oH1sccew+l0csEFFxy2zKJFi7BYLM2v1NTUboxQCCGEaM1utxMWFhbsMAJKo9H0v2Tkrbfe4oEHHuCdd94hLi7usOUWLlyI1WptfhUVFXVjlEIIIURrfTEZ6Sk1I93WTPPOO+8wf/583nvvPU466aR2yxoMBpnhTgghRI/icDjIyMgIdhgB1VOSkW6pGXnrrbeYN28eb775Jqeffnp3XFIIIUQfVVXnw+b0d/t1HQ6H1Ix0VRydPcDhcLB///7m93l5eWzZsoWoqCjS0tJYuHAhJSUlvP7668DBROSyyy7jqaeeYvLkyZSXlwNgMpmwWCwBug0hhBD9wfvfOflqTSNqNfzu3DBGD+q+yccaGhowmUzddr3u0FOSkU7XjGzYsIExY8Y0D8tdsGABY8aM4b777gOgrKyMwsLC5vL//Oc/8Xq9XH/99SQmJja/br755gDdghBCiP7Aryh8vbYRg78YfA6WrnN1ewwqlarbr9mVekoy0umakZkzZ7Y7j/2rr77a4v2yZcs6ewkhhBCiFbVKRXyUGk/lLlwMIDk2ukuv5/b42bK9nsR4I2nJIV16rWDRarV4PJ5gh9H984wIIYQQR+vWi8L51z9rGJKWyvknhnbZdXw+hRsXbmHnXjtqFTxy31A0fWTW1V/SarU0NDQEOwxZKE8IIUTvER6iYNJ7SY91o9MeucnE7fFTUu7C7z/yyrTrt9Rx6e/Xc+3tm9i0rY6de+1kJeWh03lYtqqI0NCuS36Cpdc20wghhBBHo6yikR831JAzMIycQeFHdY7Kykqys7Ox2+1HLFte2ci1t2+mps7DiJxwnv7LKHS6w/8Gf+DRXbgbHSioee41DelJ9cRaavA06cnOiOtzI2lAkhEhhBD9SJ3VwxU3b8Dh9KFSwXMPj2bk0M6PqCwrKyM7O5stW7YcsezS5ZXU1rtJjK5g2y7YttvG2BERhy2vKArJsSXERVkpseaQEFlMSOTJzMjczPDBelyuvjUVPPTiVXuFEEKIztqf58Th9DIqezsGXSNbttcf1XnKy8tJTEzsUNm0ZBOWUCs5aXvR63wkxhnbLX/vgiFEhXvYWzWVSFM5RfXD0ZrCSYwPo7y8XGpGupAkI0IIIbpczsAwBqbV0tikZ0j6fgpKXKzbXNfp81it1jbnqNq9385ziw/w7crK5m3HTYnh9Fle9KEDufWqUBLj209GpoyPZsLoMIYNiiGvdixOTxTTx1lITB3Cj2s3UWkPbXc0aW/UU5IRaaYRQgjRpVZtdfPt+gYGZtSRmnkyX329mpodW1m6IpkXHh7JsMEd6z/S4PbjV1SoVKrmBd60Wi3VtW6uv3MLniY/igJPv3SAmVNiuPGqbMymBi6/9DyWLFkCTGr3/IcSjT/dksGmHQ4iLVqSE00896mJJo+bZbtCiYxRGJrWd+Ya6SnJiNSMCCGE6DK1Nj9vfO3CWvkT1d4cKm16CqtSiYuoABTyCjs2rHRHIbzyRQ3lzij2l0FYWFhzJ9aSskbcHj+jB2xlVPY2tEoxH3xewiNP/0BEZCIhISHU1jfyyRcF1FkPP6dGQ0MDoaGh6HRqJo0OZ1BmCFYneBUdmviTUWlCqawPwEPpQXpKMiI1I0IIIbqM739Dao2+POqN/0damo6keBPOxlCS4rxMnRDVofNsOABNzjK0oYlsyoWk/yUjkZGR5AwKI2egDo9Xz57CgaTEljAiaycFeWrWbMpAYyznmx+0+P1ref29NN58YQIGQ+s5Q2pra4mMjGyxLT4SkqOhhLHotTAsve/UigDNNUzBJsmIEEKILhMboeGMKWp+XKFjYKqe06aF8H8zxrB8pUJUhJaoiI6tLRMeAuV1+wjPPBVLCISpf64Z0evUXHeJkerasWzaaeGblXpq7fWkxpZQazXx3apKqq0xDErZx/a8eIpKXQzIbD0ypra2lqiolsmRRq3ityeoqbSCJRRM+r6VjPSUmhFpphFCCNGlhiRWcfqsLG690EyoSY3BoGHi+IFUVJR2+ByzhjZhNngYlR3K8cNaNtMA5OXlctz0ESy8eTCvPj0OtzeCHfk5hIZoOPWEBJq8OrQaLymJRlIPM7V7W8kIgFqtIiFS1ecSEQC1Wo3f3/0rIP+a1IwIIYToUgUFBQwZMqTFNovFgtVq7fA5Sov2MWnMQMb/7zRhYWEcOHAAgOoaF263p3lF3dSkEP797Hh27LEzapiFuBgDGakhLPk8j79ePhaDvu3f4XV1dW0mI31ZT1n4T2pGhBBCdKny8nISEhJabFOpVOh0uiMu0ub3K6xeX8PylVsYOOjnhOZQzchDT+zmypu+5PsfoaDo586wSQkmTj4+jrgYAwADMs1kpkeDcviVfhsbGzEa2x/+K7qGJCNCCCG6jNfrRa1Wo1a3/rpJSkqipKSk3eP/8Vouf3xoKzt21/Lc4uLm7QaDgXprA19+V0FcRDXFVRF89EX7zT7R0dHU1NQc3Y2ILiXJiBBCiC5xoELhve+KadQm0eBuOVmY16eQW5/MO18X8uVG/2EnE1vxYw3R4bVUW6NYufbnREKlUqHVqggLacKgd+NoCCUhztBuPO0lI3v21+BXdJ28QxEokowIIYQIOI9XYWuBgrW6AK05jT2lLZONXUVQ2pBIU0MZP+VDQWXb55kxOZro8DqqrVFMnxTdvL26xk15ZSMnTKokLmEMV12awW/OTGk3psMlI//5oIgF961l6UoX737afk2N6BqSjAghhAg4lergy91Qi94cg+ZX3zZaDajUOlD8ze/b8rt5WYwaquWeBeO488bBAPh8Cr+7cwt5hR4O5FsZNCiNeXPT0Wra74wZGRlJfX19q+3v/7eUUKOTBncIH3ze8RE+InAkGRFCCBFwOo2Kidkq1P5GUmONDElumSgMToHxA8Cg1zFlUBPJ0W2fx2azkpkey8xpsc3JhsPppayikcq6aHJLM9m5x972wb+i0WjaXKF2yAAzkeZ6rA0RDB7Q91bm7Q0kGRFCCNElkqNUxITBlMFa9NqWyYhapeKEUWomDIthQEztYYeY5ubmkpWV1WJbeJiWqROiqaiLp7HJxKknxHc4JrVa3SohuffWQWSnq5h34RAW3jiow+cSgSPzjAghhAiamJgYqqqqSExMbLWvqsbNjp37Ofec01tsV6lULLp7GDv32oiO1JOUYOrw9SIiIqivryc6+ueqGHejneE5SZx2Wvt9TkTXkZoRIYQQQRMTE0N1dXWr7ctWV3PBNRtYt7mSV99t3btVo1ExIsfSqUREURTs7nC+WllCvf3n2pG2al/6k54wC6skI0IIIbrE4Ybr/tLhRrh8uKScUKMdhyuM9z8v69C5juTbdQ18s1HPmk1l/PnFGnw+5eAQ49w8MjIyjvn8vVVPWJ9GkhEhhBBdwuPxYDC0P/eHXq+nqamp1fYBmSHEWiqpsceRkRISkGnL9xV68BCFQVVBVZ2P5WtqmHPhSlatKef7H+qP+fy9lSQjQggh+qyGhobm9WLa01YzwbW/TWdotpszTsnh7/cNDUg8U0aa8GPCh4khyXW88V4BRm0dVmcYz7x8ICDX6I00Go0kI0IIIfoml8vVoWTkUKfSX6qrrWLUiHSuuTSD6Ch9QOIZPdjIwzfFcupJ07AVr6CsopaspHyKq5OJigjMNXojqRkRQgjRZ3U0GfllJ1ZFUVi5rpYPP11LesbggMeUGKNlxQ/1lNeYyEn7id1FQ5g6IYm/3jUs4NfqLXpCMiJDe4UQQnSJjiQjPp/Chh1qiov34PE3UVrRSHG5m1EZRazdkcYrT6ShVgd2mXu1SkVBZTqlNQmgMvOnPwwN+DV6E0lGhBBC9FkNDQ1ERUW1W+arlbUsWeElLaKE3GIwmbwMSy2n1hFNUXUjDqeX8LDALmB33bxMqus81FmbuOGKzH6diIAkI0IIIfqwjtSMWG1evH4DVmcEMZZaPD49e0py8PoNjB0RTpg58F9TSfFGnn94VMDP21tJMiKEEKLP6kgyMmdmNCvWWcktGAyeBhpcXk49IYGTZ8YzZlh4QIb0ivZJMiKEEKLP6kgyEhGu5YWHBuH1Kmg04PNzxNV3RWBJMiKEEKLPamxsxGg0dqis9n8L6Wk1XRmRaEtPSEY6PbR3xYoVnHnmmSQlJaFSqfj444/bLV9WVsbFF1/M4MGDUavV3HLLLUcZqhBCiN5Gmll6vl6ZjDidTkaNGsWzzz7bofJut5vY2FjuvvtuRo2SDkNCCCFET6LVavH5fEcu2JUxdPaAOXPmMGfOnA6Xz8jI4KmnngJg8eLFnb2cEEIIIbpQT6gZ6ZF9RtxuN263u/m9zWYLYjRCCCE6KxCr7Iru0ROSkR45HfyiRYuwWCzNr9TU1GCHJIQQohM603lVBJckI4excOFCrFZr86uoqCjYIQkhhOiEjq5LI4KvJyQjPbKZxmAwYDAYgh2GEEKIoyTJSO+h0WgkGRFCCNH3SDLSO7gafTzzcj7WmjJUhgpOPSE+KHF0upnG4XCwZcsWtmzZAkBeXh5btmyhsLAQONjEctlll7U45lB5h8NBVVUVW7ZsYefOnccevRBCiB7H52qkdPmP+PJLgh2KOIJ3Pi7m+x9qcDg8/OXJ3VTXuI98UBfodM3Ihg0bmDVrVvP7BQsWAHD55Zfz6quvUlZW1pyYHDJmzJjm/964cSNvvvkm6enp5OfnH2XYQggheqqNF/yOXFsNxlo7SbVO0q+7NNghicNodPvw+zWU1cajKOBp8gcljk4nIzNnzmx3yNarr77aapsM8RJCiP7B39RE7fI1NE0fSVhxFZVffC/JSA8296wUtmy3klug46pLU0lKCE7TmvQZEUIIETBqnY6o4yaxJ0pPyg9WYk+dGeyQRDsiI/T849ExRy7YxXrk0F4hhBC916i3nsUyehgTP3mZjN/9NtjhiF5AakaEEEIEVEVdLdkTxhI9Y0qwQxG9hNSMCCGECKj8/HzS09ODHYboRSQZEUIIEVClpaUkJSUFOwzRi0gzjRBCiIBQfF4aq0vwNjag0chvXdFx8tcihBDimCmKgjNvOwU7thBtAFfxvmCHJHoRSUaEEEIcE7uzgX15JVirK1m3t5DM+Gi8jvpghyV6EWmmEUIIcUyqaqxY6+tYtmkvM4emE2cxo4+WPiOi4yQZEUIIcUy0GjUH9u9l1ITphMRYMMfHoA0JC3ZYoheRZEQIIcQxSYyLxmG3kpKSTGxMJFqdfLWIzpG/GCGEEMfEZrOSmBBPcmJssEMRvZR0YBVCCNFpje4mnA2NKIrCvn37GDRoULBDEr2Y1IwIIYToFJu9gdLKWlAUzJom9u3ZzZi5c4MdlujFpGZECCFEp1gdDdTX17J+1Tfk79+F4vVgKysMdliiF5NkRAghRKeEmAzs2LqZ4YMG4HC6yMnOwOtpDHZYoheTZhohhBAd4vf5cNSUU5JfSGxMJClZA0iIOjiE1xwVF+ToRG8myYgQQoh2eapr2XD+NYRMyCHm8rPZsHkLs6aMJzo2DiUmBsXvR6s3BDtM0YtJM40QQoh2FS5+G9v2PewOM/HlijUMyU7HqNeh+H1otDpJRMQxk2RECCFEu3SWMBqiw3HszePkYUPITEkiJDIWjU4f7NBEHyHNNEIIIdqVesVcNhUXkLivAF2li4TpI1Gp5besCBxJRoQQQrRLrdfjHjaAM+67E51OF+xwRB8kqa0QQoh2eb1eAElERJeRZEQIIUS7ioqKSElJCXYYog+TZhohhBAtKIpCY3k+TfVVqFDYvXU3Q4cNC3ZYog+TZEQIIUQLXnst7ooCKmutNLobKauuZaq7Gp/TiibUEuzwRB8kzTRCCCFaUPw+fH4/y7YfoL6hkQkDklCpVCh+X7BDE32U1IwIIYRoQWeJocqjISMhhtED08HXhC4qCY05MtihiT5KkhEhhBAtqFRqSht8DJt2IuHJycEOR/QD0kwjhBCilbKyMhITE4MdhugnJBkRQgjRQmNjIwaDAbXMsiq6Saf/0lasWMGZZ55JUtLBDk0ff/zxEY9Zvnw548aNw2g0kpWVxT/+8Y+jiVUIIUQXa7JWs3fdclJiIoIdiuhHOp2MOJ1ORo0axbPPPtuh8nl5eZx22mnMmDGDzZs3c9ddd3HTTTfxwQcfdDpYIYQQgdVYU0rdzrVYD2zF66jHdWAzuXn5JGkaaLJWBTs80U90ugPrnDlzmDNnTofL/+Mf/yAtLY0nn3wSgJycHDZs2MDf//53zjvvvM5eXgghRAD4vR48VcU0VJdSVmMlLiIMjboIj9dHncOFJcSI390Q7DBFP9Hlo2l+/PFHZs+e3WLbKaecwssvv0xTU1Obax243W7cbnfze5vN1tVhCiFEv9DkcuKoKEZtLcfb5Gb13hJqbE5iI8KYOT2JLcW1jM5MRG0woYtMCHa4op/o8t5J5eXlxMfHt9gWHx+P1+ulurq6zWMWLVqExWJpfqWmpnZ1mEII0S9Yiw5gr61m3e5cPlm7k7jwEM6aNpoGp5P8jasoLa9i+PSTMQ+bhlpnCHa4op/olq7SKpWqxXtFUdrcfsjChQuxWq3Nr6Kioi6PUQgh+gPF72XDrv1YwsycM3kYQ5KiCYlJYlZWNF/uKmFyeiRKXRkqlYykEd2ny5tpEhISKC8vb7GtsrISrVZLdHR0m8cYDAYMBsnIhRAi0MzxadTZf2T62BGYYuLRmSNQqVWE6HVcMXkgRp0Gld4Y7DBFP9PlyciUKVP47LPPWmz7+uuvGT9+fJv9RYQQQnQdh1chOSOb2CFjWtRO64dMRl2Rhzo0Am1CZhAjFP1Rp+vhHA4HW7ZsYcuWLcDBobtbtmyhsLAQONjEctlllzWXv+666ygoKGDBggXs2rWLxYsX8/LLL3P77bcH5g6EEEJ02N69exk0aFCrZnJtdBLGodPQpw+TJhrR7Tr9F7dhwwbGjBnDmDFjAFiwYAFjxozhvvvuAw5OIXwoMQHIzMxkyZIlLFu2jNGjR/PnP/+Zp59+Wob1CiFEN1IUBcf2nziwfRtpaWnBDkeIFlTKod6kPZjNZsNisWC1WgkPDw92OEII0euUvPgCRe+/w7YBOZw+YTxJ8+YHOyTRD3T0+1vq4oQQoh+o+foLqiJjiK2rofbrJcEOR4gWJBkRQoh+IGz0WGoskcTU12IePTbY4QjRQpePphFCCBF86XfchfLcsww56yyiTj4l2OEI0YIkI0II0Q+4mpqIyMgk5rQzgh2KEK1IM40QQvQDBQUFpKenBzsMIdokyYgQQvQDkoyInkySESGE6MMUv5/yT76hdPtuIszmYIcjRJskGRFCiD5sz31PsvaSW3Cu38aWy+4IdjhCtEk6sAohRB9W+fn3OJNjMBdXUbVzU7DDEaJNUjMihBB9WOJ5p+CKtWCqspJw9snBDkeINknNiBBC9GED7r6eLTFGxsUmkXHW7GCHI0SbJBkRQog+TKVS0RQeQua5c1qt1CtETyHNNEII0cepVCpJRESPJsmIEEL0YQ0NDZhMpmCHIUS7JBkRQog+rLq6mujo6GCHIUS7JBkRQog+rLq6mpiYmGCHIUS7JBkRQog+rLq6mtjY2GCHIUS7JBkRQog+rK6ujsjIyGCHIUS7JBkRQog+yuv10tTkRa2Wf+pFzyZ/oUII0Qc5nA3szy3A42miqro22OEI0S5JRoQQog+yWu1Y6+sJCw/HanOgKEqwQxLisCQZEUKIPshg0LN//14yMrPQ6WSybdGzyV+oEEL0QUaDDr/fR2ZGOhZLmMzAKno0SUaEEKIPaSyvYvOlC9gdqibn1FnERMtIGtHzSTONEEL0Ifv/+gI1P26iLjKE6lv+RlO9LdghCXFEkowIIURfolJhS4/Hsr8UtUoF0jwjegFJRoQQopdRmtz4qopQ3A2t9g2863e4jx9DYqOPkS/9FZ0lLAgRCtE50mdECCF6EcXTiPvHT8DjAo0O/eQzUYeEN+/Xx0WjnTqa0154LIhRCtE5UjMihBC9iL++Ajwu1pZYwdeEv7qkxf7Kykri4uKCFJ0QR0eSESGE6EXUYdEoKjWri634/KC2/LwIXt2PG1n/1vtkxsQHMUIhOk+SESGE6EVUJjONQ2fi8Sl4hh6H2hIDQOWX37PujMs4sOUnii+7Fa+zdX8SIXoqSUaEEKKXqXa6CQsLw6783O2vduVaGmIi0DW4aSqvpCGvMIgRCtE5R5WMPP/882RmZmI0Ghk3bhwrV65st/xzzz1HTk4OJpOJwYMH8/rrrx9VsEIIIaCqqooBAwZgsx2cQ6RuxTL8nnoKpo8kdc02QgZkYB6YFeQohei4To+meeedd7jlllt4/vnnmTZtGv/85z+ZM2cOO3fuJC0trVX5F154gYULF/Liiy8yYcIE1q1bx9VXX01kZCRnnnlmQG5CCCH6k0PJiNVqpX7Nag7cu5D9GdmkNbgYu2gh8WeeitqgD3aYQnRYp2tGHn/8cebPn89VV11FTk4OTz75JKmpqbzwwgttlv/3v//Ntddey9y5c8nKyuLCCy9k/vz5/O1vfzvm4IUQoj9yOp0kJiZis9lw7d+HX62mOiKS1MpSwnIy0Iabgx2iEJ3SqWTE4/GwceNGZs+e3WL77NmzWb16dZvHuN1ujEZji20mk4l169bR1NR02GNsNluLlxBCCFAUBYDw8HBsNhuRs06kMTqWcIedkOwBmIcND3KEQnRep5KR6upqfD4f8fEth43Fx8dTXl7e5jGnnHIKL730Ehs3bkRRFDZs2MDixYtpamqiurq6zWMWLVqExWJpfqWmpnYmTCGE6NGcuQWsmnwG36RNoOBfbxyxvOL14ti+DU9VFVarFYvFglarxefzYUxOIequ+xj8m7nk/HMxaoPxiOcToqc5qg6sv16KWlGUwy5Pfe+99zJnzhwmT56MTqfjrLPOYt68eQBoNJo2j1m4cCFWq7X5VVRUdDRhCiFEj5T72D+xFxRhC9Gz+65FeO3Ow5ZVfD72LLiRPTdex/aLz6dw/TpiY2NblKmx20keMQK1TtfVoQvRJTqVjMTExKDRaFrVglRWVraqLTnEZDKxePFiGhoayM/Pp7CwkIyMDMLCwoiJiWnzGIPBQHh4eIuXEEL0FVpzKNbkOPadMhmVXo9K2/YPMwB3aQnObT+Rl5xKiUfP5qdfwfHWf/G5PajVanw+H1VVVa0SFCF6k04lI3q9nnHjxrF06dIW25cuXcrUqVPbPVan05GSkoJGo+Htt9/mjDPOQK2WaU6EEP1P9h+vx3/8BCJ8CpFP3ovGdPimFX1sHJqICMqiYimIS6JsQAr2/3xC0eJ3MJvN2O12PB4PBoOhG+9AiMDq9NDeBQsW8Nvf/pbx48czZcoU/vWvf1FYWMh1110HHGxiKSkpaZ5LZO/evaxbt45JkyZRV1fH448/zvbt23nttdcCeydCCNFL6CMjYNxwLjppNu889wIhN20g8//GoA0PRTtsGurQn2uD1UYjkQ/8lcRPPsX00lLs6fHoXB58DY1YLBbq6+vlh53o9TqdjMydO5eamhoefPBBysrKGD58OEuWLCE9PR2AsrIyCgt/nvnP5/Px2GOPsWfPHnQ6HbNmzWL16tVkZGQE7CaEEKI38Xg8aLVaCh58El9JPvacGKxFewgzqPHXVmA8dV6L8nl1dUycdznORgOFL71DxIyJpF11Ic6CPPLz84mKigrOjQgRICrl0DixHsxms2GxWLBardJ/RAjR6+Xm5lJeXo72r/+ibPM2fL+fgzbUgM3jZ2JxESHjTiRx7rlojAebXt544w0uuuiiVjUg+fn5fPPNN4wbN44xY8YE41aEaFdHv7+lbk8IIbqB4vfjtTlQfD7y9u4jPT2drNuuwdTkI23pek6K1RK1aTff1vnZ88DD7Lnnz/gqC6n55m2MrnpUXk+rc4aFhVFaWiqdV0Wv1+lmGiGEEJ3jLq9i3RmX4TxQACodu0+fRIzlB0Y+8ydOzP8RX6MbXZgJ86MnER4XRf64YRh/WINnTTL7qhvI0qnw7l6LbuTxzedUPI1ovnwNRfETuvJDlPOvQ6WVKeBF7yQ1I0II0cWK3/gQZ0ExxeOHUjBpCCq/n5LF79KQV4QmxIQ+KgKVzkDyJeeTuDcPtddHXkwE26ud7Le6yQ43oHhbzljdtH8b6qpiEjU+NBX5ePN2BenuhDh2kowIIUQXMybG4YiPxBtiIGZ7HplfrENt0KOLaNmGnnX7jYz/7C3Stu6m0Wggf2sBZ6eGYgiPQDtofIuyarMFgN+EHpwwTRVq6Z6bEaILSDONEEJ0saQLz8JXcIAh+4qxzIpD8fpIu+Zi9FERLcqpVCrCRwwjatokVKvWAFA9aCQZv7mk1Tm1aYMwnvAbvAW70WYNR5uU0Q13IkTXkGRECCG6QME//03Ff78m5oTpZNx8NZ6UeI7/422HXTrjl0a+9DSVn3+NLsJC9AnHHbacfuRU9CPbn3BSiN5AkhEhhAiwuh83sPe+v+EJMVK/dhNlDjuJY4d2KBEB0BiNJJ73f10cpRA9hyQjQggRANbN2yh96yPMQwZiSIzDp9Ww7ZyZRBRUoGz9iZRPl+KeOAlDbHSwQxWix5FkRAghjlFTvZUN51yJr8mNyutnyMN34zlnNinrd6J1NlIxcgD63GLq12wi/syTgx2uED2OjKYRQohj5K6oxudy8dPZJ1CflkBDXhHOaWM55alFRBVXMeSzVahDTISPGRbsUIXokaRmRAgREIrPx76HnqVu/VZSLzuXpAvOCHZI3SYkK43Gc2YTnVtIybgcIvbswW/wE3PBBUz+9h3qftxEzKypmFKSgh2qED2S1IwIIQKi+N8fsf9vL1D+4wa2XHEHzv35wQ6pW+Q+/k+WZk4kT6tw4iVzSd24g/WZcZg+/JKyDz4jfEQO6ddcQujAzGCHKkSPJTUjQohjVvHfbyh6/X0qxwykfOIQhrzxDU211hZl/K4G6j7/EH+Th8jTz0UbHhGcYAOoqc7Kgb89Q8XwbGK27aOmrhFLWRUDlm8grLKWptr6YIcoRK8gNSNCiGNS+8N6Nl98I3nWGpwJUQz4YAXFZ0xl07zbKHzp7eZyFS8+RfWHb1D73/cpfeKhIEYcOGqDHrXJSF1GErH7iggZlE382acRVVRO2NDBJM49O9ghCtErSM2IEOKYOHYfwK9WUTF6IEM+WEb8nBOpLyil2Kyj8eY/ETdnFsbkeNyFeRSao2jQ6RlWlB/ssANCE2Ji8MuPk/ffz0m99Dyyb/892tAQhj3xEGqdLtjhCdFrSM2I6Daen1bT8MlLeLb9GOxQRADFn3kSnuEDCS+qJGxgJiEZqSSu30394FTCLxiPd83H+MryiTzzN5SaIygPiSDqzPODHXbAVEeHM+nKS8l55D60oSEAkogI0UlSMyK6hbdoH+7vP8CjgD5/F+qoOLTJ2cEOSwSAIS4GywM3kWMwMXDSeLyOBuzb95ChbWD9wCxSi/OI/uxlwq64F3VuCVEGPcaTzwx22AGzf/9+Tj/99GCHIUSvJjUjIuAce3LZtfBRChe/h6IoAChOG4oCr9vNNPpBcdqDHKXojIb8IvY++ARFr7yD4vO12l9WWcGAqZNQ6/XooyKY+NnLZF9yBqeGuVnRoIMmN1Xl5cQlJTFo2HD2798fhLsIrMaySnY/9CTWfbkYNJpghyNEryY1IyKgfA0uVh93ER6rDZXPj9/lJuP6S9Fmj8AZm4baXsN2YwIzs2Typ96g+vsf2H3f32nYn4fi9YHfT5PNTtbNVzWXcbvdaLVaNL/6QtaNPp6wwr2EN3ioHTSZ0pJSsrKySE5OZsmnnzI0MxNtWFh331JAKIrC+rOvoMzTiDo2gn3upxn8wO3BDkuIXktqRkRAuSuqaaqtJ/esqTjSYrFt2wOASqfHOu4Ups4+jTzFTOGbH+EqLjvseRSfj/KPvqTswy/we73dFb74BcXvZ+sVC6gpKiZv8nC2XHoKrmgLjp17m8s05BWy8ZU3SDCFtjpeE5NIyBX3MHXeDawrrGX/xvWkJsRj//ILKlauZN0ps6n+6svuvKWAUbxeGg4UYE2JxVJQjv1/f+dCiKMjNSMioEwZKYSdOROfHsqmDefky85p3ldeXk6iokb3wVf84PaQ+NCTTPvhM/RtLBy28/Y/U/TyOwCkXH4+w595sNvuQfzM7/VSOHMMyRt2EVZWhSMphuRLzgXAVVLG6uPO5cC4wcTvKcQxcDDmIQNaHK9SqVGtXoZ12xa8ajUVf3+Q6nXbiYyMpN5iofjll4k55dRg3NoxUet0pM67gD1VxZisdlKvmBvskITo1aRmRASUSqVCdeulnPjbCxk2axTFGz+m4aMXUBqdVFZWotm+l9jdeVQOSafJasO2bVerc7gKCqj47BtKxw+hdkAyVV8tD8KdCJVaTfYTD6Ax6ImLiWHCnTdjueFyomZMYucfHmLluFOxmo00xFgwVtZSu3pDm+dxbFzHoKpiUqzVOH/agiE5mXC7HXt4OMbU1G6+q8AZ8sg9REybwKxNS4k/46RghyNErybJiAiYxpIK9vzpaXatWkPOqAGMcxWy0QG+iiKadqzB6/USP2s6WrWasIpaGoZkET56eItzVH7yMT9deAEVGZG4oi3UDUgh/uzZQbojUZ4czUl33sL0VZ8w4Ow52NyNWDdto+jlt6gYmErZ2MEMWrIajclI9IxJbZ4jbPJ0ohvsZNZWYB4/iUGLHiZt+gxUo0aTfe993XxHgeNwOIhIiMeYFB/sUITo9aSZRgSE4vfz4wmXUuFthMwEilQG4iIgXe8n160i3a/GZDIRNnwIU5Z/TOb6zaz32NGF6H8+R5OHig/epyomFntSIiPXbWXf5Zcw5Mbrg3dj/YwrP4+Cxx7FXV1PQ6WbTWMGcfl11wAHa700Gg0qowG/WkXNwFSGfLKClEvPJWvBtYSkp7R5zugzzsWYOQCf3UbYuEmodDqG33EHu957D11ERDfeXWCVl5eTmJgY7DCE6BOkZkQEhM/ZQENuIXVDUonakU/thj0YZp7H6JQ4tmmiqYlMISEhAYDQrHQyT5+Jvq6Y0refxL3yQ9y5u6m4/zrqvU4K09IZvmM70ZNHk5wzmOqamiDfXf+Rt+gv1G7fzr68Svb7PRj3F7Dnjp/768TFxeGMDCPiwQXEexXSr7mEoX+/77CJyCGhw0YSPnk6qv9NBqZWq/H7/V16L12trKys+W9aCHFsJBkRAaENM5M493Qao8Iw1TlInXceuiHjiZp7EyaNmWUvvoZm6+7meUd8B7YyLlxhfZ0Pf9EeHEs/xN7kY3fWQI6zFpF+1dUMeuTvZGdnk5ubG+S76z98jY1sHzIUZ0Q4ikpN4ta9+Fyu5v1JSUmUlpZSmRTNnKcfJmfRXUc926hKperVCUllZSXx8dJEI0QgSDIiAmb4y4uImz6eE/Z+S/wZJwDg2L0f7d9fptioperBp6j6ahkAqpBw4vQqFCCv1o1P0fCDIY7p7kpis5NIuuxytGFhpKamUpCXS+Er7/J1wiSWjzwNxx5JTtqz/2/P8W3GJNadcRmeDq4aa9+xm1VTTmN3dSPhTR6GNNSRWlJFeFQUgx9a2FwuMT6e3K3bsNXWEnGMTSzh4eHYbLZjOkcwNTU1odfrj1xQCHFE0mdEBExZeTlpQ4dgSktq3uYqKcNY72Dglz+idTfhKiwFQJM9CqXJzYTVa/hg036iS8qIHphCwtiJmGedgUp9ME/215bQWF/D1jtfxJ4YhTmviD33Pcm4d54Oyj32dM79+Rx45HmcsRE0rd1M4YtvMODOI/e52fvAY1jLqygZNp7hy7cwaV/r9YMUn4/dl95M7uB4EnblYx09AcuY4W2crWOioqKoDUBS0928dgcHXn8HX4MVv9uD2iAJiRDHSmpGRMAUFRWR+quhmtHTJxE5ZRzR+4sJyUon8dw5wMFho7qhk7HvryVl5z5qEhMI/XQZppnnoEtMaz6+sbqE5GgL++Yehy07kbJpw9CYjN16X72JWq8DlYoDJ02gLiMBtdHQoeM0JiPW1Dji9hSg07fd7OLcl0f9mo2El1QRubeQ0nc/O6ZYDyUjvc3WK29h28tv4Pt2Fbvv/muwwxGiT5BkRARMaWkpSUlJLbapDXomfPYaM3cuY/qaz9DHRLXYHzYsh6iSckZ8vxp9VBS66Jb7tSYz4wanc874oeSUWvEPTkc/ZSTWjdu7/H56I1NaMoMevw+jWoPt5CmkX31Jh44b/JeF+EbnEB8Tw8iXn2izjDEpAa0ljKzvNmKsdxA+MueYYu2tyYh10zYaosIJqbZiXb812OEI0SdIM40ICEVRDtuGrlKpMMTHtnlc8qUXogkNxVVQSOJ5Z6MxtPwlH5oxHHdNKYnnZpM+/xqcp17O9/klZNzwZ8a+8zSJ557SJffTq82YwNjsZGrz9rP7tedJGzYC84yTUalUhz3ElJqEdso4Zj05F7W67d8o2nAzk758k7J3P8OcM4CEc087pjAjIiKoq6s7pnMEQ8pvz2f/1s1EFJWT/Lv5wQ5HiD5BkhFxzCo++5YNdz1Cw5hs7KMmEDZ8UIePValUJJ77f4fdr9bqMMWnA+AqLkdZvgH/WVNwxVqo+PRbSUbaUFxcTFJYCGEr/ssmSyIh65ejDgsndMzkwx6jKAqKohw2ETnEPCiLgffcHJA4tVotvjZWAO7pBt5/G+tfepkZf76XyOFDgh2OEH3CUTXTPP/882RmZmI0Ghk3bhwrV65st/wbb7zBqFGjCAkJITExkSuuuIIamTuiz9hy5Z3UaMGwPZedty/qsusYEmIwD8kmacU2yqYPI+bkaV12rd6srKyMWI2KMK8bj1qDV63GW3H4RQkBrFYr4eHh3RThQT6HA095GdVfLkHpRUmJSqVCFRoiiYgQAdTpZOSdd97hlltu4e6772bz5s3MmDGDOXPmUFhY2Gb5VatWcdlllzF//nx27NjBe++9x/r167nqqqvaLC96H7VWiy0zgbDCSlSH6fwYqOtMXfEWEx7+I8mnHod9UAz2skKUXjxXRaAdai4LGzICw8Ac4twOaqOTCJ18PIqi4GtsbPO4YMwmuv+uO2DvbvY89Rilr7zYrdc+Vu01eQkhOq/Tycjjjz/O/Pnzueqqq8jJyeHJJ58kNTWVF154oc3ya9asISMjg5tuuonMzEymT5/Otddey4YNbS+qJXqfUW8+gZIQTfyIHIY9cU+XXksXaSH5t2cxdvRA1m7+iYbaClx1lV16zd7C52pk38dfYEaNSqcj8c5FjLzmJlyn/AY0OrZecilrpkxj5003429qanFsd88mqigKzl07CHE14DSF4Pip93QE9Xg86I5yojchRNs6lYx4PB42btzI7NktFy6bPXs2q1evbvOYqVOnUlxczJIlS1AUhYqKCt5//31OP/30w17H7XZjs9lavETP5RmYyvDzz2Tq928Qmp125AOOkeL3EWI0EmI04Ghw4e9FVfxdRfH7WXfaZaz92zPYn3qNyiXfoVKrSRk8lLKKCqq++ALHrt1UJcRTt3IV1vXrWxxfVVXVrbOJqlQqok4+hZDGRlwGI9GnzOm2ax+rYDRpCdHXdSoZqa6uxufztfpHKz4+nvLy8jaPmTp1Km+88QZz585Fr9eTkJBAREQEzzzzzGGvs2jRIiwWS/Pr13NXiJ5l7969DBrU8U6rx0qjN2KKiiMhJopKWwOmqLhuu3ZP1VhSjnXjNhyJ0YSV11D+ydcABxe2U6lQR0RSHx3N9nFjcYWY0EVHA+AqLmPNyRdT8e0qqj7+qltjTr99IYOuuwHz3EuIOf3wnZh7GqvV2usmahOipzuqDqy/bi9VFOWwbag7d+7kpptu4r777mPjxo18+eWX5OXlcd111x32/AsXLsRqtTa/ioqKjiZM0cX8bg/F/36fvI1bSIhte+huV1CpVIQlpDF04nTqPQoarVSZGxLjCMlKwx0eir7eQfRxP4+cSUxMxD1kMLWnzGZSgwvHpZdgHjwYgH0PPU3Vjt2o62z8dO1CfI3ubotZpVaTMG4cLm3PHtSn+HyUf/Q5xf9+F6+zgfr6eiwWS7DDEqJP6dS/AjExMWg0mla1IO0tGLVo0SKmTZvGHXfcAcDIkSMJDQ1lxowZPPTQQ212mjMYDBgMHZs5UgTPtuvvomDpMtyThrHrjj8z/Kk/d+v1o6Oje+WkWV1BrdUy5ovXyXv9P0y47DJiTvx5pJFx2z6WfvBfjMkJnPi3h1n86KNsueEGks86C5UKSiYOJWZnPgShT6bZbMbhcHT/hTugyWZn35/+Tu3qdTQWFQNQ8d+vsF5zsdTWChFgnaoZ0ev1jBs3jqVLl7bYvnTpUqZOndrmMQ0NDa3mLtBoNADNK7iK3ql21Voqh2URtb+YmuVruv36KpUKrVZL0686Y/ZX1Y0NDJg+uUUiUrtqHbUPPk2JxYTp5Q/IfeRxolf/yPaKKjZdeDO7VqxGHRZCosbAqBcfQdPB6eMDRa1W99h/Bw4sepriNz+iUKdi5+yplIwYSP3aTVIzIkQX6HQzzYIFC3jppZdYvHgxu3bt4tZbb6WwsLC52WXhwoVcdtllzeXPPPNMPvzwQ1544QVyc3P54YcfuOmmm5g4cWKrqcNF7+B1ONn/6PM0Dc7CFRlGREE5yReeFZRYEhMTKStrfw6N/qKttYE8NXWofT4Gf7aK0Bornqpq4iorcaFj1/8dR/HU4SR98SMTl7xGwjmnBiXuQxOu9TSe6lpsSTFYk2IZtGw99SnxxJ81B7fbjdEo6yMJEUidbqydO3cuNTU1PPjgg5SVlTF8+HCWLFlCevrBWTLLyspazDkyb9487HY7zz77LLfddhsRERGccMIJ/O1vfwvcXYhutfO2Byn5+Av2nDGdkbkVjFnybyImjglKLCkpKRTmHiA1JRmVWhOUGHqKsrIypkyZ0mJb7CkziZ41Fb5fTdT0iWTdfgu7FhQyYP02XHVefAYtOkWFJsQUpKjBaDT2yC/4zFuuZut9fyF2fwkZF/8GV2YicWecBt9+G+zQhOhzVEpP/EnyKzabDYvFIkPqeogfZpxDvteF16AnJb+CE/PXBiUOxe/DvuV7Pl+7jbPGD8I4chZqQ0hQYgk2RVF48803ueSSthfG8zc1of7F3BhNdgf7HnwK554DZNwwj9jZx3VXqK18++23DB8+vFuHFnfU+++/z2mnnkqI2UxBQQEHDhygqqqKuXPnBjs0IXqFjn5/y6q9otMyrp+HNS2BqNxSMm8K3kJhflsNWpcVj8+P4nbhq+qfo66sW3aw6uoFsHM/TTZ7m2XUv5qkSxdmZuijdzPh08VBTUSA5n+oeiK3202I2QxArFbHT8tX4N22HVdxSZAjE6JvkWREdIgzt4DaVevwNzWRNPf/CJ19HCet+oSsBdcELSaVMQRQEWs2UuloRGUKC1oswaL4/Ww8/xoK9uyD79ew78Engh1Sp4WHh/fIZKShoQGT6efmq3333o85Nw9l1x523/HHIEYmRN/Tswf4ix6h6uvlbLrkBvD7iTp+Mhn/fJi4pERMaclBjUttNGMYNp2BbKHA6iIjqnvXVukJlCYvTfU2nMMziN92AHdFVbBD6jSLxXLYta0CxVVQQNkHH2NKSyXh3LNRHWF1YoDS0tIWnew9lVWkVlWhqFR4zP0v8RWiK0kyIo6o7IPPaQwPpTYrCZavwbP1J7Kzs4MdFgCaiDiyp5zEurfe6peLl6kNegbeczN7Nq0nDA1ZtwavpupoWSyWLl3ywe92s+XSeXisNlR+P35XI8m/vfiIx5WWlpKRkdH8PvPWm3H/4Y8ofoXM+27usniF6I8kGRFHZBk/imJbFV6DngiPl/Kt2xgzflyww2qmVqsxmUw4HA7M/2vf74sURaHmu2X4XC5iZ5+EWq8HIOvmq4j+j5ETFj+PStP7RhQdGk3TVTy1tTTV1bNz0ngydu/DsXfvEY+pW7uRvPUbGT9kaPO2mBNnMXXNKqB1HxwhxLGRPiPisPxeL/sXPUfumo1EDB3MZK+W/EGp1O/Yzc4rbg12eC1kxUez84dv8FR2bXV/d/J7POQ//Qy777gT25at5D/9PDtuuJXdd9zFztt+7rPg9XrR6nS9MhE5pCsH9RkSEgiZdTyOiHAq01NIOOfsdstX/PcrNp43D+vOPWw+b16LFY7VOp0kIkJ0AakZEYdV+M832P/wc+w9cxoZL/2AevQQUncU0mgxU7crD7/Xi7oHrCvis9eRpNTzXUEhOZE61IYQtJaYYId1zIoXv0Lx4lfxqdXUrlyFPiGZurgY3CEm1Ct/aC5XV1dHZGRkECM9NrVffIJz83r2/biUtIV/xpCUEtDzq1Qq3Beez2y3hy35eYSPGdVu+Zplq/GEhqBzNeLKK6CxtJyQdJn+XYiuJDUjok0V//2O0veWUD52EKHlNejrbEROGY+ltIr4XXlEnzC9RyQiAP6mRkx6LR6vHwDF0xjkiALDXVFJXUwMW6ZNxu9yEXXcNEoHZFKTlEj0SbOay9XU1BD9v1V4ext/o4uKl5/H6HZhq6mm+r3/BPT87vJKDjz2PDt/WM3wGdOJT0qisrKy3WNiTj4eR5QFc3U9oYMHYEzufx2jhehuPePbRPQolV8uZ8M5v6N2WDoNWfFkfrOBpIvPJvvOG4ieOZWm2jpiTgzu3BS/pLXEoTZHoFKByhSONioh2CEFRNLFF7GsrBSd24PuoguIu2Y+Ef95A7fHw5Df/bzqdU1NDcnJwR3ZdNQ0GlQ6HXEOG2XmSJKMgZsJtslqY8NvrqDS5USVlki+5kViLWF89fafGBsWRc4j96AxtZ71Ne6UE4i01RHr9TP8zNN6TNItRF8mNSOihYaCQkre+BB7ehx1Q1JJ++96xrz1HCP/sQiVSkXk5HHEnXYSaoM+2KE2U2k0hORMxRyfhjp7HCpN3/jy0KalYj5uBhfcfx95UdGsfvs9xkyfRvKQwVTX1TWX6801I2qdnpQ/3M+A+BjK07KJvfiKgJy38KX/sHzYNGpraykYN4yE3XnUr9lA1R//Ro0Git/6mMKX3jzs8fX4GXreWWjNoQGJRwjRvr7xr7YIiIbcfNb/3/lYtXrKpo4g+/0VhOUMIPaEtldk7klUKhXmsDCcTichIb17SnjF56Pwpdf56cB+MidNoPG7VdT+sJZScwhRS1eS/uCdFBQUEBcXB9DrRxGZx0zAPGYCuz//nFpXI3FhR7/kg7u8igOPvkDZBx9RlZVC1cB0Bi5fj8HlJvbUE6n+bi16pwuvyYDPdfjmvKamJvT6npNwC9HXSc2IaFa3dj0+t4fcKaPJWb+BYQ/dxPS1H7RZld0ThYaG4nQ6gx3GMSt96wMOLHqCvLpaHHf/haolS0nevpeY/BJsazeQHJ/QapKwvjDHSkp5GV/efRfbr7oST01Nq/1NVhu2rdvwu914a6so+dOtFNxwEdalnzWX2XrNHRS8+QH7Jo7AGR3BkKU/kjh+DNNWf0Ha/EvIuu1ajO4mDFPGkHZ123ONNDY2YjAYuuw+hRCtSc2IaBYxcTyOpHgslTWEGPQkX3Q2GmPv+Uc5NDQUh8MR7DCOmau4lCaTEV2jG3Wjm/CxIwn7cR1hNfVYJo7DZNBTvz+Xwlf+Q8w5Z/SJL05PVRWul17ENn4i9s0bKXvjP6Tf9PPEYq7CIjadfwlem42QAVlknDsLV1E+do0O/1svYp5yPBpzOK6CYqqzUzBVWUktKiN53kVkLfgduggLAAPvugn7pk2YTCb0kRFtxlJeXt4jF+0Toi+TZEQ0C83ORPX7q5jo9ZN1/AyMib2rI6jZbKa6ujrYYRyz5It/w87lKwmttRI752SybruByGmT8FTVEDt7Frv+cC/+6kp+2vkh/hffxDNuGK5JUzClJB355D2USqtFpVYT0uDEo9ej/lWCVfXVNzTZ7ZQOyCR5fy5NdWOp1IdyIDSK6fVFqNQH51gZsPBG9r/+BhFFFQz5670kXXBmq2tZLBaqqg4/bX55eTmJiTKCRojuJMmIaKYoCtYmD8MuvTTYoRyV0NBQCgoKgh3GMTOlpRB7zwIGh4QwaPRoVCoVUVMnNe+3bfmJWJ+XfRPGoHW5idq8g523Pci4d/4RxKiPjS4ykuz7HiB3yeeETJ9O4q/+Bs1DB+MKDeHA6OEkFZcRcfZF1H7wFm5nI3Fz70AdcrCjafKFZxFnUJg2cRJRhxmSGxERwb59+9rc5zxwgPyNmxhy7jmBvUEhRLukz4gAoPrbZaxceB8RjoZgh3LUzGZzn2imAaisriZ54MA2+4IkXfgbLFU1DPl0BbG7C7AUVOC19/6+MjGnnELaBXOJm3812tCWHXKjpk0l/LabsegNxD3+MCFZ2dhTsjENzCF0fMsO1g0eNxGJh29mOdxaONZNm9l4zgVUbdvGnsvn42twBebGhBBHJMmIwLF7L9t+dwt7CgvgpdepXfVjsEM6KiEhITQ09N5k6pecTiehoW0PK824/homfPouOfffRmydA3N4OIMfvKObI+waRqORxsa2R7nUmUM4+TfnUeb34fP5UKlUqNtYfdfv97e5/RCtVovP52u1vXb5SrxaLRqvD3dpGc79+4/+RoQQnSLNNILGklJ8ahWuMDOhVjuuwiJgSrDD6jS1Wt2la5x0F7/fj0qlaneEjDlnMOacwWRcH5h5OXoKk8l02GTEarUyePBgNm3aRGlpKUlJSZSWlqIoSkBGE0VMmUTF998TW1KKLiaakKzMYz6nEKJjJBkRRE6dhG3aJGLzizClpxJ76snBDqlf6+1rzRwLo9HYognF19iI2mDA4/Gg1+tRq9UYDAZ27drF4MGDqaurw+VyNc8tc6RakUN0Ol3zOf1uNyq9nsjJk/CcdgrTo2KIm3U82l48d4sQvY0kI/1ck9VG7ep1WCeO5fwH7iEkMaHXT38dqF/KwVJRUdFvh5Yeaqbxe73svu126n/4gdCcIYT88Y8kJyfT1OQjNDyajRvXMmT4WEJCQnA4HM3JiMPhOGzz1i9ZLBbqqqqwP/U3nD9tQZ8xCGXmHKLi4kg999yuvk0hxK/07m8dcUy8DidrTzmfMnyo4qPxT56GOjWwK6Z2N71ej8fj6dVzb1RUVDB48OBghxEUJpMJl8uFdd066n/4gcqEBMzrd1H5+D8YevIJ1A52Eh2bSHhEJI4GD0ZTSIuJ7ux2O2FhYUe8jsVioWzdj6h+2kKeJR7V8h1UVjSQWGXDM/ME9FERXXiXQohfkw6s/VTZO++y4bQzsdbVUTx6CPE7D1D1zfJgh3XMevMsrL5GNz9dewc73/wA26vv9Yn+L51lNBpxu93ooqIAyMvI5KcpEyhVQ9EVd+Mtq8QcFs6MmacCEParEVQdTUYiIiJwqjU4DUZKomIpHzYAlyUM/b58rBu2dMm9CSEOT5KRfshdWUneo49SZdSz7/jxDFixAV2jh8jJ44Md2jHrzbOwlr7zMRUff4HX56XoqRexbvwp2CF1O4PBQGNjI+YhQxjwwP0YNDqyPvyBqB35qL0+2LmXmEgzERYzqYlRhIeHHXXNiCs0jPrTz2W4Vk3Wqi3kfPED2tAQwkYO7cpbFEK0QZpp+qFD/SmKsjIZs3EjEZPHkX79NUSMGx3cwALAbDb32poRlUqNolKh9vkPvu9AR8y+5pcjoqJOPZVoqxXLVz+hW78Xc042cacehy78546lLrOZ3Nzc5vd2u53U1NQjXiciIoL6+noajCHMefoZ7FftpH79FmJOnIExIS7wNyaEaJckI/2QPjaWrD/+ka0/rCJ22lQG/flBtB34NdkbhIaGtjmhVW+QNPcsStZvwmSvI+uO3xM+ZniwQwoqp9OJOSKC43/6HFdBKaaMZNQ6XYsyv26W60jNiKIoOGoqyM/LZeiQQSh+P+GjhhE+aliX3IcQ4sgkGemnEn5zHhFNHoZedFGwQwkos9lMaWlpsMM4KmqDnqQ//B5Pfj7ZM2YEO5ygczqdmM1m1Ho9oQMz2ixzqMPrIQ0NDc0jaw7H7XLictgwGY1kpSThtNUTFhkdyNCFEJ3U/+qBBfDzxFp9jUmno76slKJH/sTeqy+m+qN3gh1Sp9hsNsLDw4MdRo/QkWG6bU10d6S/a7Xm4G+wObNmYA4NQaPRHFugQohjJjUj/VR70433Vp6aGvbOu5KKjBSqyg7g0htoevWfhI2fjCE1PdjhdYjVau33K8ZqNBp8Pl+X/Y3qDUYi45NpsNVjCAnFFGYJ+DWEEJ0jyUgf4XM1UPryv/BUVRJ/wcWYh7Xf38But/e5X+A1S7/BW1qKfXgOG9MGoajVDLZVEPX2v4gYPRyN0YA2ZxLqmORgh3pYNpuNIUOGBDuMoDo0osbpdBITE9OhYxRFoampqcO1HKGWSEIt/XOWWyF6IklG+oiyV1+m8uMP8alV2DdvZOQH/23V2e+XbDZbh4ZA9ibG9DQAJn23DHOkAVNSDKsSMglrctNUnIdFp8ZQUYjh3BtRqbu3al7xeXFs347GbMZnt6GPT8CQmNSqXEeHpvZlh/qBdHQ2VaPRSPnyNWy49m5qc1IoxUzSBad1Q6RCiECRZKSPaKqtoT4snJLYeIbn7kXxeKCdZMRutxMREdF9AXaDyClTGPiXP2PbsJHoE0/EX7CdGcu/JtcyiDKbH5/iZ3a8G3xe6OZk5MB9d2Fd/QNq7f8WwNNoyF70OGGjx7Yo5/V60bXzufUHh6aEP9SB9UhCQ0PZtuh5nP4mtLU2tt/4gCQjQvQyR9WB9fnnnyczMxOj0ci4ceNYuXLlYcvOmzeveQXSX76GDZNhdIEUP/cS7DGxNBoMJF52BZoj/KLsq7/A4047jQH33UvktKmEn3gmIeHhjKjIY2asDrtXQTtiOipd904V73M6sa7+gQMp6awbOpq1OaPwaDTUL/u2W+PoLYxGIy6XC4/H06HELDQ0FH9UONWjsonYX4bO0reaH4XoDzqdjLzzzjvccsst3H333WzevJkZM2YwZ84cCgsL2yz/1FNPUVZW1vwqKioiKiqK888//5iDFz8LGTAQzZnnoB87nsTLrjxi+b6ajPySLj6RlL+9RNIjrxJy4R2oErPQDp/WrTH4PR5s61ZhT0vHEWpm4s4tpFSVUxoZQ8jQlgm5z+frkyOcOstkMtHY2AgceWSMoihQUoprwiBCkuJJHT2Mse8+0x1hCiECqNPNNI8//jjz58/nqquuAuDJJ5/kq6++4oUXXmDRokWtylssFiyWn3urf/zxx9TV1XHFFVccQ9iiLXaHA4PR1KGyHZmPoS9QqdWo9AdrQtQaTYeXmA+UokX3Yd28gZ3Zw5lp0BBzyi3Euhr4vt5O1MlzWpR1OBx9PkHsCKPRSH19fYfKlvz7TSpeeY2dUydygq2GSUsWd21wQogu0al/lT0eDxs3bmT27Nktts+ePZvVq1d36Bwvv/wyJ510EunpvWOoZW/h8/mav2Q7usBaf/sVHh4e3u2zszq2bORAbBLZ1aUYmxqJO+c3pFx8Gaa4eBoaGlqUlTlGDjIajTQ0NHQoaaxd8QMhdgfpO3bTtHYDfo+nGyIUQgRap5KR6upqfD4f8fHxLbbHx8dTXl5+xOPLysr44osvmmtVDsftdmOz2Vq8RPuqq6uJjo7GYDDgkX+Q2xQZGUldXV23XjNs4hSqzRYSrTWETz2ueXtGWAQrHnuOis+WNm+zWq2SjHCwmaa2trZDNXcxJ83C5Gwgbc9+IqZMQq3Xd0OEQohAO6r66l//olYUpUO/sl999VUiIiI4++yz2y23aNGi5uYdi8XSoYWv+rvy8nISExMx/2pJ9bZ4vV602v43kCoYyUjybfdgGDiY7D8/Rsw5cwHwVNdSc93d7DtwgC3zbqHiv98AB2tGftmk2V8ZjUaqq6s7NKw36cLzGf2fVxj61GOMeOHpbohOCNEVOpWMxMTEoNFoWtWCVFZWtqot+TVFUVi8eDG//e1v0R/h18vChQuxWq3Nr6Kios6E2S+VlZWRkJCA2WzGbre3W9Zut3doyGRf05XJiKIoOH/ahO2H5S2aCiqqq0kZMpTQEaObtzXkFYHNgcrnw2vUY9u6A5BmmkM6k4wAWMaNIXb2iagN3TtKSggROJ1KRvR6PePGjWPp0qUtti9dupSpU6e2e+zy5cvZv38/8+fPP+J1DAYD4eHhLV6ibYrPR/1n71K+ZQOhdZUdqhnpDyNp2tKVyUjd5x9R+Kc7KXn8IYofvq95e0FBQav+UeEjcwgbmUNYaTUNaYkknHsaJW9+QuF3q3B8vapL4utNtFotfr+/XybMQvRXnW6mWbBgAS+99BKLFy9m165d3HrrrRQWFnLdddcBB2s1LrvsslbHvfzyy0yaNInhw/v3suiBZlv6KbUf/QdvfS0Vj91HiE7TbjKi+P1UbN+Fyevvxih7Br1eT1NTU5ec275+NXXGUPIj4nBu3Yji8wFQVFTUqplRbdAz+cs3mXb3Aix3/Z6mmnq2XnUnrrJKtl/5B+rWbemSGHsTk8nU59ZOEkIcXqc7DsydO5eamhoefPBBysrKGD58OEuWLGn+9VdWVtZqzhGr1coHH3zAU089FZioRTNvTSVWfQjhTY0oHg8hKnW7ycjW+bexozCP0DoH6Y/9iZhZ3TvvRl9lHj+F/BobPrWaYWkp+D0eKj/9CEdxGdo2RjepDXqyZ01n/dtv02Dz4tNp4X/lXIWlRE4c3c130HPYdx1AbW+gceNOyMgIdjhCiG5wVL0Yf//73/P73/++zX2vvvpqq20Wi6XVMEYRGGGzTqNk63ZSHLWYp55AaFo6jt172izrqa2n4tOvcc8YTURBOSX/+bDfJSOHFmEzGo0BPW/k6efgLipHqyikXH0NBx64h+KtW9AlJJH/6MNk3XN/q2PUajUajYaok47HdeIEIvcWEz5mGHGnHh/Q2HoTT3UtP0w7H9+5U9nz9zuJNBiJP+OEYIclhOhi/W9IRR+jT0rFOnISs08/DX1kFIqi4HK5UBSF6u9WozR5iT15OiqNBm24GUNyAq5oC8Y6O2Ejc4IdfrczuVzkfb2UwXNObXchwc4qLi4mc+gwysrKUOv1OHdspy7MQoS1HueOnw57XEpKChW2eprOO4lzjpuFOTkBVTdOytbTOPcV4LM7idxZiMbjpX79T5KMCNEPSDLSyzU0NGAwGtFHRgE/D7ve+8CTHHj0nwCYhw4g9qTpZP/hOjJef4LKz75g+JN/IvmSc4MWdzAUv/ZvbO++zw6vF/93yxj25GPHfE5/UxPlb/2HNYXFTJ4zh7KygyNrYv/vbLb98AMpZSXEXjbvsMeHl9bw3adfEhIfS1hq61V8+5vwMUMxDxsI6/egCTGReN6pwQ5JCNENJBnpxXwNTnat+ZEBWVmt9pV98AXWjASqRmUTsz0P+/P/piG/mPqrz2HalZeSnJwchIiDq3rpt5gcDupjY6j5blmH58dpT9l/XqP0tcVUjRpHzQN3Y5h3DY2NjSRdeTValZZx06cRPmhwm8fad+2n4Mo/UnrTuQx64V0qh40m7pTj2izbX2iMBqb/+D71G7YROjADY0JssEMSQnSD/lsf3Mt5SovIvf63bPvvxxjffw3F+/MoEbVaTcyc46kenknS6h00xEaQN3s8tas3k7txC4lHmBOmr4qcMY2wunrsUZFETpkUkOnw3SUlVMTGEVNbg89mI8xkwmazHTy3yXTYRATAVVCC2ucn48v1mEuqacgtOOZ4+gKNyUj0jAmSiAjRj0gy0kvZVn2Pp7ERj1qL6sBuGg/sbd4XGhpKwh+uwTx5NANPmUXS2l2Yi6rYOT0H37fr2Pdg/1zVNO2aqxj59OOYhw5h4N//BoDi8zYPw+0sRVGIOu0MClIySC8uJPb/ziYyLg6r1dqh9YGiZ04mYsIooncVEJKRQuJ5px1VHEII0dtJM00vZUjPYm9kAlnWSlR6Pbr4xOZ9ZrOZrT/9xPAZUxm1YAJDHrqdb1Km4dPpsBwoo7YpcB03exOVSkX0zOMZoNNSWlVF/M5N1Lz+HCqNhphr78A0bGyHz+UqLGHNKZdRGG4gZcZ4xr73EfqYWDz79lFfX4/D4TjipF0ao4Ep379FY0k5hoTYgHaoFUKI3kRqRnoh+5rl1G/bSH3mYEZMP460Bx5DG3GwA6uvwYVr9UbWr1xFZkQkAIa4aJIvPpOEtbsxVVtJ+e3ZQYw++LKzs8nNzaXu/VepUemw+fzUf/SfTp0j/x9v4Cwtp2ZoOpp/vEdTvRM4OIzdarVSW1tLVFTUEc+jUqsxpSZJIiKE6NckGellGrZvpvL5R/hxx24G7d9C5EmnYcwe1Lx/972PUP/RlxhKKtn921uat49a/Dcmf/cfZmz6lNQrfhOEyHuO+Ph4ygoL8RpD+dGSwo7QODSWyE6dwxAXjTvcTGhlHRq1Bq3l4JIFnU1GhBBCSDNNr9NUXoJHrcGmMzDOZaOpohR9clrzfufeXMwVtSSv20lDeU3ziBGVWk30jAlBjLznKFr8PvVfruRzrZqxaVp2RycQftHVnTpHxu9/S25tNarScsa/fz2G2IOJh8FgwOPxUFtbK0sfCCFEB0nNSC8TOmEaRfHpZDpq0KdlYRo2usX+jOvnYXB7sRRXknnzVQEZMdLX5D72IuG5ZagcjTj+vZbhJ8xmf1lFhzqdHqLW6zGcPJXx991K7OwZrfbX1dURGdm52hYhhOivpGakl9FaIqkcPpFzZx2HKTEFlUbTYn/cqbOYuWs5PpcLU3LiYc7Sv5mHDSL602+J3lFA2PQJxO7PZcnyZTh272HYM08TNqJjNRo1NTWMGzeu1XaVSoXb7Uav1wc6dCGE6JMkGelFPPu2U7JlHRa1hpCU9MOW00dFABHdFVavM+qlRYQ9sRilyUvmzZez4bTT0YwcgaPRTcEL/2D488926DwNDQ2EhIS02m42m6murg502EII0WdJMhJgiqLQ1NiIsuEr/OX5aAaMRjf6+GNuLvGWFWJ9/XG2qiMY6HPSVDgNXdqAAEXdv+gsYQx+4Gbg4OelDQsjsqYaa3QUqR1sWjlck45z/34avvwav0aNdeRmLGPHBCxuIYToq6TPSAD5fT7KCnKp2/gdDfu2Ul5rxbt1Of6q4mM+t7e6DL+iUIOeWDx4K0sDELFQqVQMffZpEjIyYewYsm5f0KHjHA4HYWFhrbYf+Msi1IWF6MvL2XfPvYEOVwgh+iRJRgLI5XTgbfKwak8hS6phtVVh095Kip55Avu61cd0bv3AEVRYEklSGtFERGPIGR2YoAVhw4Yy6ZGHUUaNRPe/mpEjdWatrq4mJiam9Q6/n9iKCpIKi1D8/q4IVwgh+hxJRgJIq9dTWVUN5gjmDE1lZmM1u1wq8g/kUbjoPpqqq4763GpjCEU5Uxhz8dVE3bwIdWh4ACMXh4bkApS89E82nzKTnfMvw1PV9mdWVVXVZjKSddcfCU9NxRIbw8AHH+jCiIUQou+QZCSADEYTBwpLGDd+PMaZv0GbPZaJhXvZG58Cfj8+h+2oz+33+6mtqydhyDBUMltnl1Cr1TSUFFPx1r+pDTXTUFRA5Yfvtln2cDUj5sGDGfP+u4z79BMiJk7s6pCFEKJPkA6sAbKn1M/eglocTTrSMgegVqvQnXom1hXfgUqFZdZsDOlZnTqnoih4Kirx7dnAgY1rSDTHoHi9qLTysXWFqKgo6l2NoFbz08Ac0stLSf7V+jI+t4ftNzxArsrJoN3lRC64MkjRCiFE3yE1IwFQ61DYVaJQuHc9poSJFNUc7G+gi45l4D/+jWXCFBJuuL1TI2oUv5/t1y1g02ln4fz+I3bY3GSU7sK95Yeuuo1+LzY2lnqPh8jbFxKn0VAzaAiGxFg8RbnNZYoWv0fxax/gbXCx586/YftpdxAjFkKIvkGSkQDwK6D4fTQ6qgmJSML/i76PKpWKyOho6uvrO3VO5/5cqr76lqKsdD4jljg8ROJF8XkDG7xoFhcXR2VlJRWWSCZccgkjGyv54avPqXrsLtwHDiYdiqeJphAjWtfB/iV+T1MwQxZCiD5BkpEAiDaD2ZePJTaDxAhIi2lZAxIVFUVtbW2nzqmPicYdFUGVOZzJ235ipLoR3aCRGMdMD2Dk4pdiY2Oprq4mPz+fZK2KFHsV5boQ/IB77zYAUuefj+bM4wmvdZD9h2uwjJP1Z4QQ4lhJ54MAUKlUuKp3c97JM4iM1LTaHxUVRWVlZYfP56uvwbdtNdbfnsW40lrM02cQfeWlqNSSO3Ylf00N1Xv2EhISgunMM7BbIon2uLFpDMT/byi11hyK6fL/Y8Lw4SQkJAQ3YCGE6CMkGTlGiqLgtddjs1oPuzBaVFQUu3d3rG+B4vNif+1RKh0NaH0mRp8/G+PEEwMZsmiD4vWy9bdX0DQwC11JGaWWSJL+8Agp336FNyYBfcbA5rJVVVXExcUFMVohhOhbJBk5Borfj/Wt59i/aydxJgu+uio0kbGtyoWHh2Oz/TysV1EUKq3g9UNiBKjVPzfrKA1O/HYrP/ojmKWx4ysv6o5b6fe8djvu8goStRoiqmtx7NqFxnw5qROns2vXruZy/v9NZKaWWiohhAgY+Rf1GHjLi/Ds3EiuOpQsVw2uDSvaLKdWqw/WoPgUthX6+W67wg97FdbuV1h34Ofern5HPd78rWwPSyJD5SZMDfoRk7vrdvo1bUQE0SfOIq64FENTE/FnnwX83I/kkIqKCqkVEUKIAJOakWOgNoeDWoNDpSFcaUIT0cb04IfKqtVsK/Syv0KNsyaX+pKfCIvNRq0aCfxvTpGNX1FntVGInvNOmIlhxHGowyO66W76N5VKxdDHH8Wxazf6mBgMCfEAaLVavN6DI5j8rgbyNm8kOT0jiJEKIUTfIzUjx0ATHonqN9dhiYwi9NQLMI6bcdiyFouFmlor1tKfsFfuJTZrKo7qXOIj/ldAUcDdwJYKO9NTI9CYTJKIdDOVRkPY8GHNicghBoMBZ3kZRXdew/7vv0L96lP4nI4gRSmEEH2PJCPHqExlYOAJcwidcVq7o10iIyII95dhLf2J+CGzGZAej1nnYlL2wf4iKrUabfZo6hu9RIca0WaM6K5bEEcQFxdH0ZoVNNnqadTo0FaV4dq5JdhhCSFEnyHNNMeooKCA4447rt0y3spStN++xw8eI9Oy0xgzXotBp6Jgsw6fz4tafXCtGW32GJSoHZhPuhCVRj6aniIuLo5auxWbOYa0hnpQq9Enpwc7LCGE6DPkG+8Y2Ww2LBZLu2UaVn9NuMuORmMgc8+PaF0XgC6yecbP5ORk4H/L1qvUkoj0MMaCAg5s2IgrdTBnZyYQNmYS+qTUYIclhBB9hjTTHCVFUaiosWE0hRyxrCY8EgtNnO0rR6XTozIYAUhISKC8vLy5nMvlIiTkyOcT3adh3z4qHryfQk8T8evWYsgajnHg0GCHJYQQfYr8BD8KiqKwtaCJPbtz8emSsDr9WEIPn9eFHHcaSpMHX00FpqknozaYgIPJyKpVq5rL1dXVHXbiNBEc7rJSVCgM3b2ThIpyGktKCB8/IdhhCSFEn3JUNSPPP/88mZmZGI1Gxo0bx8qVK9st73a7ufvuu0lPT8dgMJCdnc3ixYuPKuCeoLEJaux+rFVFhMekUlrna7e8SqvDfMr5WC6+AX3G4ObtFoulxWRokoz0POETJhIyaDDJ5aUYU1KJmjkr2CEJIUSf0+makXfeeYdbbrmF559/nmnTpvHPf/6TOXPmsHPnTtLS0to85oILLqCiooKXX36ZAQMGUFlZ2Tx3Q2+k14JWAy5HHcbQSMxG1ZEPOgyv1Urt2rVETpxIXV0dGRkZgQtUHDONycTQFxfjqapCHxODSiuViUIIEWgqRVGUIxf72aRJkxg7diwvvPBC87acnBzOPvtsFi1a1Kr8l19+yYUXXkhubi5RUVFHFeShTqJWq5Xw8PCjOkeglVfVs/TbZZww+wySIjWoVJ1PSPKffobv160jqbCQgWedxfaBAzjhhBMwm81dELEQQgjRvTr6/d2pZhqPx8PGjRuZPXt2i+2zZ89m9erVbR7z6aefMn78eB555BGSk5MZNGgQt99+Oy6X67DXcbvd2Gy2Fq+eprwkn9HDskmO0h5VIgJQ9cWXhNfXY42MpPqLL3E6nYSGhgY4UiGEEKJn61QyUl1djc/nIz6+5QyV8fHxLUaF/FJubi6rVq1i+/btfPTRRzz55JO8//77XH/99Ye9zqJFi7BYLM2v1NSeN4wyLy+PrKysYzpH5JTJxFRUUJWYSMTkySiKctSJjRBCCNFbHVUH1l9/Ybb3Jer3+1GpVLzxxhtMnDiR0047jccff5xXX331sLUjCxcuxGq1Nr+Kirp+5Vqvw8n2G//EutOvovr7H9st6/f5AlKLkbXwj+Q88AAxw4cRcf3v0Gg0x3Q+IYQQojfqVG+8mJgYNBpNq1qQysrKVrUlhyQmJpKcnNxiYrCcnBwURaG4uJiBAwe2OsZgMGAwGDoT2jHb/9cXyP/X2/h1GmpWrufksh/Rhrae88O5fAkFX3yI2RRNU2kBuqSjn4lTrdMRd/ppTMrP55uPP8Msc4wIIYTohzpVM6LX6xk3bhxLly5tsX3p0qVMnTq1zWOmTZtGaWkpDsfPC4vt3bsXtVpNSkrKUYTcNdxVtTQkRZF71hT8rkb8rsZWZZQmD/bP36JQbSSpsR7Ht58E5Nq2R1+hcNceav7xDrlPvBKQcwohhBC9RaebaRYsWMBLL73E4sWL2bVrF7feeiuFhYVcd911wMEmlssuu6y5/MUXX0x0dDRXXHEFO3fuZMWKFdxxxx1ceeWVmEymwN3JMcq+bT6NORk0JEWTec/16GNaj/xprKimQW+iRBtKsq8BdWhYQK5d+sYnxK/fi6mijuJ/fxSQcwohhBC9RacnTZg7dy41NTU8+OCDlJWVMXz4cJYsWUJ6+sHmirKyMgoLC5vLm81mli5dyo033sj48eOJjo7mggsu4KGHHgrcXQSAeUg2ofPPZXJEBLo25kvZ99fn2XP/UxReMpPjB0Do8BmEzbkgINeOmjEB31crQIHoc04LyDmFEEKI3qLT84wEQ3fNM/LGG28wZ84cfvzxR04//fQW+74IG0nVgETcllCGerVMW/VuwK7rdTZQ8p9P0ISYSLroDNQysZYQQog+oEvmGenL7HY7ZrOZqKgoqopKqFm5HsXnQ1EUbFu3oxqQQs2oLBLX7MY8+NiG9P6aNjSE9GsvIuW3Z0siIoQQot+Rb77/KSoqIjU1lZI3P6Xx42/57s8vkz1rGhFjssh75l/sP34Sw6obSL/zGrLvuDrY4QohhBB9Rr9ORvxNTbgratDFRJK/ey/jpk0h/+5nidhbQu3wDELe+ZyGPUlUZqdhrqvHXGdj8J9uCXbYQgghRJ/Sb5ORxpIKVp9wIY1FZai0WvaePZW4974lcsoYqr75garxA/GNGYw/2UJlbBjDl/6A5SzpXCqEEEIEWr9NRkre/pTG4nIKTxiDX6NB5fVT+clSBt19AyFZqYS99Skbc5LQuJsYWlLP4AfvIumCc4IdthBCCNHn9NtkJCQrFRSFhPW7QQFNkxe10YAxIY7wSweT+9hLxBW4aAoLwbermJTP3wx2yEIIIUSf1G+TkYSzT2HYUw9Qt3YTGoMBf1MTqfPORx8TeXD/uadif/CZg/99yf8FM1QhhBCiT5N5Rg5DURRqvvsRX4OL2DnHy5BbIYQQopM6+v0t37CHoVKpiDmx7fV2hBBCCBE4MumZEEIIIYJKkhEhhBBCBJUkI0IIIYQIKklGhBBCCBFUkowIIYQQIqgkGRFCCCFEUEkyIoQQQoigkmRECCGEEEElyYgQQgghgkqSESGEEEIElSQjQgghhAgqSUaEEEIIEVS9YqG8QwsL22y2IEcihBBCiI469L196Hv8cHpFMmK32wFITU0NciRCCCGE6Cy73Y7FYjnsfpVypHSlB/D7/ZSWlhIWFoZKpTrm89lsNlJTUykqKiI8PDwAEYrOkOcfXPL8g0uef3DJ8+9eiqJgt9tJSkpCrT58z5BeUTOiVqtJSUkJ+HnDw8PljzGI5PkHlzz/4JLnH1zy/LtPezUih0gHViGEEEIElSQjQgghhAiqfpmMGAwG7r//fgwGQ7BD6Zfk+QeXPP/gkucfXPL8e6Ze0YFVCCGEEH1Xv6wZEUIIIUTPIcmIEEIIIYJKkhEhhBBCBJUkI0IIIYQIqn6ZjDz//PNkZmZiNBoZN24cK1euDHZIfdIDDzyASqVq8UpISGjerygKDzzwAElJSZhMJmbOnMmOHTuCGHHvtmLFCs4880ySkpJQqVR8/PHHLfZ35Hm73W5uvPFGYmJiCA0N5f/+7/8oLi7uxrvovY70/OfNm9fq/4fJkye3KCPP/+gsWrSICRMmEBYWRlxcHGeffTZ79uxpUUb+/nu2fpeMvPPOO9xyyy3cfffdbN68mRkzZjBnzhwKCwuDHVqfNGzYMMrKyppf27Zta973yCOP8Pjjj/Pss8+yfv16EhISOPnkk5vXIhKd43Q6GTVqFM8++2yb+zvyvG+55RY++ugj3n77bVatWoXD4eCMM87A5/N11230Wkd6/gCnnnpqi/8flixZ0mK/PP+js3z5cq6//nrWrFnD0qVL8Xq9zJ49G6fT2VxG/v57OKWfmThxonLddde12DZkyBDlj3/8Y5Ai6rvuv/9+ZdSoUW3u8/v9SkJCgvLwww83b2tsbFQsFovyj3/8o5si7LsA5aOPPmp+35HnXV9fr+h0OuXtt99uLlNSUqKo1Wrlyy+/7LbY+4JfP39FUZTLL79cOeussw57jDz/wKmsrFQAZfny5YqiyN9/b9CvakY8Hg8bN25k9uzZLbbPnj2b1atXBymqvm3fvn0kJSWRmZnJhRdeSG5uLgB5eXmUl5e3+CwMBgPHH3+8fBZdoCPPe+PGjTQ1NbUok5SUxPDhw+UzCZBly5YRFxfHoEGDuPrqq6msrGzeJ88/cKxWKwBRUVGA/P33Bv0qGamursbn8xEfH99ie3x8POXl5UGKqu+aNGkSr7/+Ol999RUvvvgi5eXlTJ06lZqamubnLZ9F9+jI8y4vL0ev1xMZGXnYMuLozZkzhzfeeIPvvvuOxx57jPXr13PCCSfgdrsBef6BoigKCxYsYPr06QwfPhyQv//eoFes2htoKpWqxXtFUVptE8duzpw5zf89YsQIpkyZQnZ2Nq+99lpzxz35LLrX0Txv+UwCY+7cuc3/PXz4cMaPH096ejqff/4555577mGPk+ffOTfccAM//fQTq1atarVP/v57rn5VMxITE4NGo2mV5VZWVrbKmEXghYaGMmLECPbt29c8qkY+i+7RkeedkJCAx+Ohrq7usGVE4CQmJpKens6+ffsAef6BcOONN/Lpp5/y/fffk5KS0rxd/v57vn6VjOj1esaNG8fSpUtbbF+6dClTp04NUlT9h9vtZteuXSQmJpKZmUlCQkKLz8Lj8bB8+XL5LLpAR573uHHj0Ol0LcqUlZWxfft2+Uy6QE1NDUVFRSQmJgLy/I+FoijccMMNfPjhh3z33XdkZma22C9//71A0LrOBsnbb7+t6HQ65eWXX1Z27typ3HLLLUpoaKiSn58f7ND6nNtuu01ZtmyZkpubq6xZs0Y544wzlLCwsOZn/fDDDysWi0X58MMPlW3btikXXXSRkpiYqNhstiBH3jvZ7XZl8+bNyubNmxVAefzxx5XNmzcrBQUFiqJ07Hlfd911SkpKivLNN98omzZtUk444QRl1KhRitfrDdZt9RrtPX+73a7cdtttyurVq5W8vDzl+++/V6ZMmaIkJyfL8w+A3/3ud4rFYlGWLVumlJWVNb8aGhqay8jff8/W75IRRVGU5557TklPT1f0er0yduzY5uFfIrDmzp2rJCYmKjqdTklKSlLOPfdcZceOHc37/X6/cv/99ysJCQmKwWBQjjvuOGXbtm1BjLh3+/777xWg1evyyy9XFKVjz9vlcik33HCDEhUVpZhMJuWMM85QCgsLg3A3vU97z7+hoUGZPXu2Ehsbq+h0OiUtLU25/PLLWz1bef5Hp63nDiivvPJKcxn5++/ZVIqiKN1dGyOEEEIIcUi/6jMihBBCiJ5HkhEhhBBCBJUkI0IIIYQIKklGhBBCCBFUkowIIYQQIqgkGRFCCCFEUEkyIoQQQoigkmRECCGEEEElyYgQQgghgkqSESGEEEIElSQjQgghhAgqSUaEEEIIEVT/DzWNqz+/aVqJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "action_list = []\n",
    "price_list = []\n",
    "n_list = []\n",
    "index = 0\n",
    "for n in X_test:\n",
    "    action = policy.select_action(np.array(n))\n",
    "    action_list.append(action)\n",
    "    price_list.append(n[0])\n",
    "    index +=1\n",
    "    n_list.append(index)\n",
    "\n",
    "\n",
    "# 製作figure  \n",
    "fig = plt.figure()   \n",
    "\n",
    "#圖表的設定\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "#直線圖\n",
    "ax.plot(n_list,price_list, color='grey',linewidth=0.5,label='price trend')\n",
    "#散佈圖\n",
    "norm = plt.Normalize(-1, 1)\n",
    "ax.scatter(n_list, price_list, c=norm(action_list), cmap='coolwarm',s=3);\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 紅色為正值 藍色為負值\n",
    "# print('本次測試結果，將會賺得：' + str(money-100000) + '元(本金為100000)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.98514026], dtype=float32),\n",
       " array([0.9852126], dtype=float32),\n",
       " array([0.9971565], dtype=float32),\n",
       " array([0.9973749], dtype=float32),\n",
       " array([0.9970003], dtype=float32),\n",
       " array([0.95273274], dtype=float32),\n",
       " array([0.996435], dtype=float32),\n",
       " array([0.66524017], dtype=float32),\n",
       " array([-0.22234258], dtype=float32),\n",
       " array([0.6458989], dtype=float32),\n",
       " array([-0.2978787], dtype=float32),\n",
       " array([0.03400561], dtype=float32),\n",
       " array([0.4729993], dtype=float32),\n",
       " array([0.8199528], dtype=float32),\n",
       " array([0.6451355], dtype=float32),\n",
       " array([-0.32343873], dtype=float32),\n",
       " array([-0.31747216], dtype=float32),\n",
       " array([0.9072822], dtype=float32),\n",
       " array([0.9955931], dtype=float32),\n",
       " array([0.32550538], dtype=float32),\n",
       " array([0.5959248], dtype=float32),\n",
       " array([0.9468811], dtype=float32),\n",
       " array([0.62156147], dtype=float32),\n",
       " array([0.6343209], dtype=float32),\n",
       " array([0.7627515], dtype=float32),\n",
       " array([0.7874703], dtype=float32),\n",
       " array([0.745507], dtype=float32),\n",
       " array([0.85896665], dtype=float32),\n",
       " array([0.9739956], dtype=float32),\n",
       " array([0.9905212], dtype=float32),\n",
       " array([0.99016035], dtype=float32),\n",
       " array([0.9962622], dtype=float32),\n",
       " array([0.974926], dtype=float32),\n",
       " array([0.90151954], dtype=float32),\n",
       " array([0.95922655], dtype=float32),\n",
       " array([0.9409924], dtype=float32),\n",
       " array([0.93739754], dtype=float32),\n",
       " array([0.995214], dtype=float32),\n",
       " array([0.98310626], dtype=float32),\n",
       " array([0.9693644], dtype=float32),\n",
       " array([0.9632571], dtype=float32),\n",
       " array([0.9720187], dtype=float32),\n",
       " array([0.97465724], dtype=float32),\n",
       " array([0.99889904], dtype=float32),\n",
       " array([0.9988042], dtype=float32),\n",
       " array([0.99390584], dtype=float32),\n",
       " array([0.5117334], dtype=float32),\n",
       " array([0.9728825], dtype=float32),\n",
       " array([0.5411047], dtype=float32),\n",
       " array([0.9648278], dtype=float32),\n",
       " array([0.44465578], dtype=float32),\n",
       " array([0.9376021], dtype=float32),\n",
       " array([0.6768094], dtype=float32),\n",
       " array([0.88766694], dtype=float32),\n",
       " array([0.97767067], dtype=float32),\n",
       " array([0.14928077], dtype=float32),\n",
       " array([0.9978667], dtype=float32),\n",
       " array([0.99525726], dtype=float32),\n",
       " array([0.10145738], dtype=float32),\n",
       " array([0.2563982], dtype=float32),\n",
       " array([0.21731809], dtype=float32),\n",
       " array([0.9114019], dtype=float32),\n",
       " array([0.8148639], dtype=float32),\n",
       " array([0.7390344], dtype=float32),\n",
       " array([0.43492395], dtype=float32),\n",
       " array([0.92391044], dtype=float32),\n",
       " array([0.9981389], dtype=float32),\n",
       " array([0.72513413], dtype=float32),\n",
       " array([0.91952276], dtype=float32),\n",
       " array([0.92554], dtype=float32),\n",
       " array([0.8522142], dtype=float32),\n",
       " array([0.69198847], dtype=float32),\n",
       " array([0.88136995], dtype=float32),\n",
       " array([0.75315225], dtype=float32),\n",
       " array([0.99637717], dtype=float32),\n",
       " array([0.9845285], dtype=float32),\n",
       " array([0.8703464], dtype=float32),\n",
       " array([0.8027378], dtype=float32),\n",
       " array([0.9078616], dtype=float32),\n",
       " array([0.87444144], dtype=float32),\n",
       " array([0.81268305], dtype=float32),\n",
       " array([0.8597711], dtype=float32),\n",
       " array([0.84713715], dtype=float32),\n",
       " array([0.97340405], dtype=float32),\n",
       " array([0.99114925], dtype=float32),\n",
       " array([0.9910025], dtype=float32),\n",
       " array([0.961541], dtype=float32),\n",
       " array([0.945344], dtype=float32),\n",
       " array([0.9146651], dtype=float32),\n",
       " array([0.9494571], dtype=float32),\n",
       " array([0.9362146], dtype=float32),\n",
       " array([0.94117403], dtype=float32),\n",
       " array([0.9748392], dtype=float32),\n",
       " array([0.97506815], dtype=float32),\n",
       " array([0.9834707], dtype=float32),\n",
       " array([0.97272855], dtype=float32),\n",
       " array([0.7493641], dtype=float32),\n",
       " array([0.97214013], dtype=float32),\n",
       " array([0.9113348], dtype=float32),\n",
       " array([0.89929277], dtype=float32),\n",
       " array([0.98184705], dtype=float32),\n",
       " array([0.9798697], dtype=float32),\n",
       " array([0.963287], dtype=float32),\n",
       " array([0.8756023], dtype=float32),\n",
       " array([0.96612024], dtype=float32),\n",
       " array([0.97562766], dtype=float32),\n",
       " array([0.9716431], dtype=float32),\n",
       " array([0.97021425], dtype=float32),\n",
       " array([0.9735978], dtype=float32),\n",
       " array([0.97408193], dtype=float32),\n",
       " array([0.9788556], dtype=float32),\n",
       " array([0.987492], dtype=float32),\n",
       " array([0.9856429], dtype=float32),\n",
       " array([0.5265162], dtype=float32),\n",
       " array([0.8076598], dtype=float32),\n",
       " array([0.77785724], dtype=float32),\n",
       " array([0.89362144], dtype=float32),\n",
       " array([0.8564179], dtype=float32),\n",
       " array([0.7974625], dtype=float32),\n",
       " array([0.8899864], dtype=float32),\n",
       " array([0.9998452], dtype=float32),\n",
       " array([0.9014873], dtype=float32),\n",
       " array([0.9979996], dtype=float32),\n",
       " array([0.93403274], dtype=float32),\n",
       " array([-0.06160239], dtype=float32),\n",
       " array([0.7492791], dtype=float32),\n",
       " array([0.93041503], dtype=float32),\n",
       " array([0.9975464], dtype=float32),\n",
       " array([0.97087187], dtype=float32),\n",
       " array([0.9542434], dtype=float32),\n",
       " array([0.9605809], dtype=float32),\n",
       " array([0.9251298], dtype=float32),\n",
       " array([0.9729491], dtype=float32),\n",
       " array([0.05087033], dtype=float32),\n",
       " array([0.8435272], dtype=float32),\n",
       " array([0.9670278], dtype=float32),\n",
       " array([0.9286864], dtype=float32),\n",
       " array([0.95921564], dtype=float32),\n",
       " array([0.9651592], dtype=float32),\n",
       " array([0.9607065], dtype=float32),\n",
       " array([0.9217681], dtype=float32),\n",
       " array([0.9683461], dtype=float32),\n",
       " array([0.9731595], dtype=float32),\n",
       " array([0.9613222], dtype=float32),\n",
       " array([0.9664005], dtype=float32),\n",
       " array([0.95931613], dtype=float32),\n",
       " array([0.9638981], dtype=float32),\n",
       " array([0.97324294], dtype=float32),\n",
       " array([0.974191], dtype=float32),\n",
       " array([0.9891024], dtype=float32),\n",
       " array([0.97357255], dtype=float32),\n",
       " array([0.9809085], dtype=float32),\n",
       " array([0.44148478], dtype=float32),\n",
       " array([0.9459976], dtype=float32),\n",
       " array([0.9457245], dtype=float32),\n",
       " array([0.3713896], dtype=float32),\n",
       " array([0.8655168], dtype=float32),\n",
       " array([0.9906017], dtype=float32),\n",
       " array([0.3175498], dtype=float32),\n",
       " array([0.5530313], dtype=float32),\n",
       " array([0.87117183], dtype=float32),\n",
       " array([0.9715293], dtype=float32),\n",
       " array([0.9959494], dtype=float32),\n",
       " array([-0.01645916], dtype=float32),\n",
       " array([0.99252176], dtype=float32),\n",
       " array([0.85919005], dtype=float32),\n",
       " array([0.09514381], dtype=float32),\n",
       " array([0.1741511], dtype=float32),\n",
       " array([0.13733333], dtype=float32),\n",
       " array([0.2574839], dtype=float32),\n",
       " array([0.18729267], dtype=float32),\n",
       " array([0.15705687], dtype=float32),\n",
       " array([0.1904504], dtype=float32),\n",
       " array([0.97517955], dtype=float32),\n",
       " array([0.0705477], dtype=float32),\n",
       " array([-0.04012586], dtype=float32),\n",
       " array([0.07297978], dtype=float32),\n",
       " array([-0.03598698], dtype=float32),\n",
       " array([0.16871573], dtype=float32),\n",
       " array([0.97812074], dtype=float32),\n",
       " array([-0.3197391], dtype=float32),\n",
       " array([-0.7079474], dtype=float32),\n",
       " array([-0.9994988], dtype=float32),\n",
       " array([-0.978452], dtype=float32),\n",
       " array([-0.5227219], dtype=float32),\n",
       " array([-0.9136441], dtype=float32),\n",
       " array([-0.99420756], dtype=float32),\n",
       " array([-0.96520126], dtype=float32),\n",
       " array([-0.9733732], dtype=float32),\n",
       " array([-0.99384093], dtype=float32),\n",
       " array([-0.43573594], dtype=float32),\n",
       " array([-0.7275436], dtype=float32),\n",
       " array([-0.9964532], dtype=float32),\n",
       " array([-0.9995367], dtype=float32),\n",
       " array([-0.99999267], dtype=float32),\n",
       " array([-0.99985844], dtype=float32),\n",
       " array([-0.9999907], dtype=float32),\n",
       " array([-0.9989834], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-0.7786514], dtype=float32),\n",
       " array([-0.9911359], dtype=float32),\n",
       " array([-0.99971557], dtype=float32),\n",
       " array([-0.9783208], dtype=float32),\n",
       " array([-0.99995655], dtype=float32),\n",
       " array([-0.9000646], dtype=float32),\n",
       " array([-0.9985204], dtype=float32),\n",
       " array([-0.53953344], dtype=float32),\n",
       " array([0.7065921], dtype=float32),\n",
       " array([-0.9660855], dtype=float32),\n",
       " array([-0.99475026], dtype=float32),\n",
       " array([-0.9985119], dtype=float32),\n",
       " array([-0.9999996], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-0.99989593], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-0.99999255], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-0.9921363], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-1.], dtype=float32),\n",
       " array([-0.9986828], dtype=float32),\n",
       " array([-0.9933275], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_list[:]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TD3_Ant.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
